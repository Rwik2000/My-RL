{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WXu1r8qvSzWf"
   },
   "source": [
    "# Twin-Delayed DDPG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YRzQUhuUTc0J"
   },
   "source": [
    "## Installing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HAHMB0Ze8fU0"
   },
   "outputs": [],
   "source": [
    "!pip install pybullet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xjm2onHdT-Av"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ikr2p0Js8iB4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pybullet_envs\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from gym import wrappers\n",
    "from torch.autograd import Variable\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y2nGdtlKVydr"
   },
   "source": [
    "## Step 1: We initialize the Experience Replay memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u5rW0IDB8nTO"
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "\n",
    "  def __init__(self, max_size=1e6):\n",
    "    # An element of torage basically stores a tuple of : state, next_state, action, reward, done\n",
    "    self.storage = []\n",
    "    self.max_size = max_size\n",
    "    self.ptr = 0\n",
    "\n",
    "  def add(self, transition):\n",
    "    if len(self.storage) == self.max_size:\n",
    "      self.storage[int(self.ptr)] = transition\n",
    "      # Moving the pointer in circular manner.\n",
    "      self.ptr = (self.ptr + 1) % self.max_size\n",
    "    else:\n",
    "      self.storage.append(transition)\n",
    "\n",
    "  def sample(self, batch_size):\n",
    "    ind = np.random.randint(0, len(self.storage), size=batch_size)\n",
    "    batch_states, batch_next_states, batch_actions, batch_rewards, batch_dones = [], [], [], [], []\n",
    "    for i in ind: \n",
    "      state, next_state, action, reward, done = self.storage[i]\n",
    "      batch_states.append(np.array(state, copy=False))\n",
    "      batch_next_states.append(np.array(next_state, copy=False))\n",
    "      batch_actions.append(np.array(action, copy=False))\n",
    "      batch_rewards.append(np.array(reward, copy=False))\n",
    "      batch_dones.append(np.array(done, copy=False))\n",
    "    return np.array(batch_states), np.array(batch_next_states), np.array(batch_actions), np.array(batch_rewards).reshape(-1, 1), np.array(batch_dones).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jb7TTaHxWbQD"
   },
   "source": [
    "## Step 2: We build one neural network for the Actor model and one neural network for the Actor target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4CeRW4D79HL0"
   },
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "  \n",
    "  def __init__(self, state_dim, action_dim, max_action):\n",
    "    super(Actor, self).__init__()\n",
    "    self.layer_1 = nn.Linear(state_dim, 400)\n",
    "    self.layer_2 = nn.Linear(400, 300)\n",
    "    self.layer_3 = nn.Linear(300, action_dim)\n",
    "    self.max_action = max_action\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.layer_1(x))\n",
    "    x = F.relu(self.layer_2(x))\n",
    "    x = self.max_action * torch.tanh(self.layer_3(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HRDDce8FXef7"
   },
   "source": [
    "## Step 3: We build two neural networks for the two Critic models and two neural networks for the two Critic targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCee7gwR9Jrs"
   },
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "  \n",
    "  def __init__(self, state_dim, action_dim):\n",
    "    super(Critic, self).__init__()\n",
    "    # Defining the first Critic neural network\n",
    "    self.layer_1 = nn.Linear(state_dim + action_dim, 400)\n",
    "    self.layer_2 = nn.Linear(400, 300)\n",
    "    self.layer_3 = nn.Linear(300, 1)\n",
    "    # # Defining the second Critic neural network\n",
    "    # self.layer_4 = nn.Linear(state_dim + action_dim, 400)\n",
    "    # self.layer_5 = nn.Linear(400, 300)\n",
    "    # self.layer_6 = nn.Linear(300, 1)\n",
    "\n",
    "  def forward(self, x, u):\n",
    "    xu = torch.cat([x, u], 1)\n",
    "    # Forward-Propagation on the first Critic Neural Network\n",
    "    x1 = F.relu(self.layer_1(xu))\n",
    "    x1 = F.relu(self.layer_2(x1))\n",
    "    x1 = self.layer_3(x1)\n",
    "    # # Forward-Propagation on the second Critic Neural Network\n",
    "    # x2 = F.relu(self.layer_4(xu))\n",
    "    # x2 = F.relu(self.layer_5(x2))\n",
    "    # x2 = self.layer_6(x2)\n",
    "    return x1\n",
    "\n",
    "  # def Q1(self, x, u):\n",
    "  #   xu = torch.cat([x, u], 1)\n",
    "  #   x1 = F.relu(self.layer_1(xu))\n",
    "  #   x1 = F.relu(self.layer_2(x1))\n",
    "  #   x1 = self.layer_3(x1)\n",
    "  #   return x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzIDuONodenW"
   },
   "source": [
    "## Steps 4 to 15: Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zzd0H1xukdKe"
   },
   "outputs": [],
   "source": [
    "# Selecting the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Building the whole Training Process into a class\n",
    "\n",
    "class TD3(object):\n",
    "  \n",
    "  def __init__(self, state_dim, action_dim, max_action):\n",
    "    self.actor = Actor(state_dim, action_dim, max_action).to(device)\n",
    "    self.actor_target = Actor(state_dim, action_dim, max_action).to(device)\n",
    "    self.actor_target.load_state_dict(self.actor.state_dict())\n",
    "    self.actor_optimizer = torch.optim.Adam(self.actor.parameters())\n",
    "    self.critic = Critic(state_dim, action_dim).to(device)\n",
    "    self.critic_target = Critic(state_dim, action_dim).to(device)\n",
    "    self.critic_target.load_state_dict(self.critic.state_dict())\n",
    "    self.critic_optimizer = torch.optim.Adam(self.critic.parameters())\n",
    "    self.max_action = max_action\n",
    "\n",
    "  def select_action(self, state):\n",
    "    state = torch.Tensor(state.reshape(1, -1)).to(device)\n",
    "    return self.actor(state).cpu().data.numpy().flatten()\n",
    "\n",
    "  def train(self, replay_buffer, iterations, batch_size=100, discount=0.99, tau=0.005, policy_noise=0.2, noise_clip=0.5, policy_freq=2):\n",
    "    \n",
    "    for it in range(iterations):\n",
    "      \n",
    "      # Step 4: We sample a batch of transitions (s, s’, a, r) from the memory\n",
    "      batch_states, batch_next_states, batch_actions, batch_rewards, batch_dones = replay_buffer.sample(batch_size)\n",
    "      # converting numpy to torch tensors\n",
    "      state = torch.Tensor(batch_states).to(device)\n",
    "      next_state = torch.Tensor(batch_next_states).to(device)\n",
    "      action = torch.Tensor(batch_actions).to(device)\n",
    "      reward = torch.Tensor(batch_rewards).to(device)\n",
    "      done = torch.Tensor(batch_dones).to(device)\n",
    "      \n",
    "      # Step 5: From the next state s’, the Actor target plays the next action a’\n",
    "      next_action = self.actor_target(next_state)\n",
    "      \n",
    "      # Step 6: We add Gaussian noise to this next action a’ and we clamp it in a range of values supported by the environment\n",
    "      noise = torch.Tensor(batch_actions).data.normal_(0, policy_noise).to(device)\n",
    "      noise = noise.clamp(-noise_clip, noise_clip)\n",
    "      next_action = (next_action + noise).clamp(-self.max_action, self.max_action)\n",
    "      \n",
    "      # Step 7: The two Critic targets take each the couple (s’, a’) as input and return two Q-values Qt1(s’,a’) and Qt2(s’,a’) as outputs\n",
    "      target_Q1 = self.critic_target(next_state, next_action)\n",
    "      \n",
    "      # Step 8: We keep the minimum of these two Q-values: min(Qt1, Qt2)\n",
    "      # target_Q = torch.min(target_Q1, target_Q2)\n",
    "      \n",
    "      # Step 9: We get the final target of the two Critic models, which is: Qt = r + γ * min(Qt1, Qt2), where γ is the discount factor\n",
    "      target_Q1 = reward + ((1 - done) * discount * target_Q1).detach()\n",
    "      \n",
    "      # Step 10: The two Critic models take each the couple (s, a) as input and return two Q-values Q1(s,a) and Q2(s,a) as outputs\n",
    "      current_Q1 = self.critic(state, action)\n",
    "      \n",
    "      # Step 11: We compute the loss coming from the two Critic models: Critic Loss = MSE_Loss(Q1(s,a), Qt) + MSE_Loss(Q2(s,a), Qt)\n",
    "      critic_loss = F.mse_loss(current_Q1, target_Q1) \n",
    "            \n",
    "      # Step 12: We backpropagate this Critic loss and update the parameters of the two Critic models with a SGD optimizer\n",
    "      self.critic_optimizer.zero_grad()\n",
    "      critic_loss.backward()\n",
    "      self.critic_optimizer.step()\n",
    "      \n",
    "      # Step 13: Once every two iterations, we update our Actor model by performing gradient ascent on the output of the first Critic model\n",
    "      if it % policy_freq == 0:\n",
    "        actor_loss = -self.critic.forward(state, self.actor(state)).mean()\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "        \n",
    "        # Step 14: Still once every two iterations, we update the weights of the Actor target by polyak averaging\n",
    "        for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
    "          target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
    "        \n",
    "        # Step 15: Still once every two iterations, we update the weights of the Critic target by polyak averaging\n",
    "        for param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
    "          target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
    "  \n",
    "  # Making a save method to save a trained model\n",
    "  def save(self, filename, directory):\n",
    "    torch.save(self.actor.state_dict(), '%s/%s_actor.pth' % (directory, filename))\n",
    "    torch.save(self.critic.state_dict(), '%s/%s_critic.pth' % (directory, filename))\n",
    "  \n",
    "  # Making a load method to load a pre-trained model\n",
    "  def load(self, filename, directory):\n",
    "    self.actor.load_state_dict(torch.load('%s/%s_actor.pth' % (directory, filename)))\n",
    "    self.critic.load_state_dict(torch.load('%s/%s_critic.pth' % (directory, filename)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ka-ZRtQvjBex"
   },
   "source": [
    "## We make a function that evaluates the policy by calculating its average reward over 10 episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qabqiYdp9wDM"
   },
   "outputs": [],
   "source": [
    "def evaluate_policy(policy, eval_episodes=10):\n",
    "  avg_reward = 0.\n",
    "  for _ in range(eval_episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "      action = policy.select_action(np.array(obs))\n",
    "      obs, reward, done, _ = env.step(action)\n",
    "      avg_reward += reward\n",
    "  avg_reward /= eval_episodes\n",
    "  print (\"---------------------------------------\")\n",
    "  print (\"Average Reward over the Evaluation Step: %f\" % (avg_reward))\n",
    "  print (\"---------------------------------------\")\n",
    "  return avg_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gGuKmH_ijf7U"
   },
   "source": [
    "## We set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFj6wbAo97lk"
   },
   "outputs": [],
   "source": [
    "env_name = \"AntBulletEnv-v0\" # Name of a environment (set it to any Continous environment you want)\n",
    "seed = 0 # Random seed number\n",
    "start_timesteps = 1e4 # Number of iterations/timesteps before which the model randomly chooses an action, and after which it starts to use the policy network\n",
    "eval_freq = 5e3 # How often the evaluation step is performed (after how many timesteps)\n",
    "max_timesteps = 1e6 # Total number of iterations/timesteps\n",
    "save_models = True # Boolean checker whether or not to save the pre-trained model\n",
    "expl_noise = 0.1 # Exploration noise - STD value of exploration Gaussian noise\n",
    "batch_size = 100 # Size of the batch\n",
    "discount = 0.99 # Discount factor gamma, used in the calculation of the total discounted reward\n",
    "tau = 0.005 # Target network update rate\n",
    "policy_noise = 0.2 # STD of Gaussian noise added to the actions for the exploration purposes\n",
    "noise_clip = 0.5 # Maximum value of the Gaussian noise added to the actions (policy)\n",
    "policy_freq = 2 # Number of iterations to wait before the policy network (Actor model) is updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hjwf2HCol3XP"
   },
   "source": [
    "## We create a file name for the two saved models: the Actor and Critic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fyH8N5z-o3o"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------------------------------------\nSettings: TD3_AntBulletEnv-v0_0\n---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "file_name = \"%s_%s_%s\" % (\"TD3\", env_name, str(seed))\n",
    "print (\"---------------------------------------\")\n",
    "print (\"Settings: %s\" % (file_name))\n",
    "print (\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kop-C96Aml8O"
   },
   "source": [
    "## We create a folder inside which will be saved the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Src07lvY-zXb"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./results\"):\n",
    "  os.makedirs(\"./results\")\n",
    "if save_models and not os.path.exists(\"./pytorch_models\"):\n",
    "  os.makedirs(\"./pytorch_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qEAzOd47mv1Z"
   },
   "source": [
    "## We create the PyBullet environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CyQXJUIs-6BV"
   },
   "outputs": [],
   "source": [
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5YdPG4HXnNsh"
   },
   "source": [
    "## We set seeds and we get the necessary information on the states and actions in the chosen environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z3RufYec_ADj"
   },
   "outputs": [],
   "source": [
    "env.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "max_action = float(env.action_space.high[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HWEgDAQxnbem"
   },
   "source": [
    "## We create the policy network (the Actor model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTVvG7F8_EWg"
   },
   "outputs": [],
   "source": [
    "policy = TD3(state_dim, action_dim, max_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZI60VN2Unklh"
   },
   "source": [
    "## We create the Experience Replay memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sd-ZsdXR_LgV"
   },
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QYOpCyiDnw7s"
   },
   "source": [
    "## We define a list where all the evaluation results over 10 episodes are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhC_5XJ__Orp"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------------------------------------\nAverage Reward over the Evaluation Step: 9.804960\n---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "evaluations = [evaluate_policy(policy)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xm-4b3p6rglE"
   },
   "source": [
    "## We create a new folder directory in which the final results (videos of the agent) will be populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MTL9uMd0ru03"
   },
   "outputs": [],
   "source": [
    "def mkdir(base, name):\n",
    "    path = os.path.join(base, name)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    return path\n",
    "work_dir = mkdir('exp', 'brs')\n",
    "monitor_dir = mkdir(work_dir, 'monitor')\n",
    "max_episode_steps = env._max_episode_steps\n",
    "save_env_vid = False\n",
    "if save_env_vid:\n",
    "  env = wrappers.Monitor(env, monitor_dir, force = True)\n",
    "  env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31n5eb03p-Fm"
   },
   "source": [
    "## We initialize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1vN5EvxK_QhT"
   },
   "outputs": [],
   "source": [
    "total_timesteps = 0\n",
    "timesteps_since_eval = 0\n",
    "episode_num = 0\n",
    "done = True\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q9gsjvtPqLgT"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_ouY4NH_Y0I"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Timesteps: 20 Episode Num: 1 Reward: 6.068686682889529\n",
      "Total Timesteps: 1020 Episode Num: 2 Reward: 507.69299053362005\n",
      "Total Timesteps: 2020 Episode Num: 3 Reward: 517.4511899392827\n",
      "Total Timesteps: 3020 Episode Num: 4 Reward: 523.0192113282028\n",
      "Total Timesteps: 4020 Episode Num: 5 Reward: 505.8667123717637\n",
      "Total Timesteps: 4877 Episode Num: 6 Reward: 424.6922218798735\n",
      "Total Timesteps: 5452 Episode Num: 7 Reward: 310.51535759277914\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 204.307338\n",
      "---------------------------------------\n",
      "Total Timesteps: 5844 Episode Num: 8 Reward: 178.20208350652246\n",
      "Total Timesteps: 6844 Episode Num: 9 Reward: 505.1644712672619\n",
      "Total Timesteps: 7244 Episode Num: 10 Reward: 194.1645843188322\n",
      "Total Timesteps: 8244 Episode Num: 11 Reward: 487.3589116447002\n",
      "Total Timesteps: 9244 Episode Num: 12 Reward: 307.5418296754723\n",
      "Total Timesteps: 10244 Episode Num: 13 Reward: 324.5562594771561\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: -92.826476\n",
      "---------------------------------------\n",
      "Total Timesteps: 11244 Episode Num: 14 Reward: -114.98001113886092\n",
      "Total Timesteps: 12244 Episode Num: 15 Reward: 179.05862485745828\n",
      "Total Timesteps: 13244 Episode Num: 16 Reward: 73.67451677793477\n",
      "Total Timesteps: 13365 Episode Num: 17 Reward: 5.098784578911763\n",
      "Total Timesteps: 13839 Episode Num: 18 Reward: 25.209274986904852\n",
      "Total Timesteps: 13958 Episode Num: 19 Reward: -0.6991639079359582\n",
      "Total Timesteps: 14958 Episode Num: 20 Reward: 104.50604095324094\n",
      "Total Timesteps: 15000 Episode Num: 21 Reward: 6.236807911035997\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 42.747748\n",
      "---------------------------------------\n",
      "Total Timesteps: 15583 Episode Num: 22 Reward: 49.66962577514143\n",
      "Total Timesteps: 16072 Episode Num: 23 Reward: 44.61522570664725\n",
      "Total Timesteps: 16242 Episode Num: 24 Reward: 16.14451413956669\n",
      "Total Timesteps: 16296 Episode Num: 25 Reward: 8.302156105554507\n",
      "Total Timesteps: 16537 Episode Num: 26 Reward: 18.609123893517836\n",
      "Total Timesteps: 16761 Episode Num: 27 Reward: 18.60696156255143\n",
      "Total Timesteps: 16951 Episode Num: 28 Reward: 11.89845158475377\n",
      "Total Timesteps: 17924 Episode Num: 29 Reward: 89.5886119354143\n",
      "Total Timesteps: 18027 Episode Num: 30 Reward: 2.2298310045293306\n",
      "Total Timesteps: 18051 Episode Num: 31 Reward: -1.2308821525969567\n",
      "Total Timesteps: 18225 Episode Num: 32 Reward: 7.9684048219584085\n",
      "Total Timesteps: 18377 Episode Num: 33 Reward: 8.218408125921354\n",
      "Total Timesteps: 18431 Episode Num: 34 Reward: 1.7909881277575939\n",
      "Total Timesteps: 18579 Episode Num: 35 Reward: 7.999808354085563\n",
      "Total Timesteps: 18774 Episode Num: 36 Reward: 11.47937114054407\n",
      "Total Timesteps: 18798 Episode Num: 37 Reward: -1.9156497447468426\n",
      "Total Timesteps: 18822 Episode Num: 38 Reward: -0.43763096992797423\n",
      "Total Timesteps: 18879 Episode Num: 39 Reward: 1.3667151550529688\n",
      "Total Timesteps: 19168 Episode Num: 40 Reward: 22.052697653671565\n",
      "Total Timesteps: 19513 Episode Num: 41 Reward: 60.00436339883781\n",
      "Total Timesteps: 19697 Episode Num: 42 Reward: 27.242983214381862\n",
      "Total Timesteps: 20460 Episode Num: 43 Reward: 68.05903975335823\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 34.168083\n",
      "---------------------------------------\n",
      "Total Timesteps: 21430 Episode Num: 44 Reward: 88.67723433822128\n",
      "Total Timesteps: 22430 Episode Num: 45 Reward: 82.54104416449736\n",
      "Total Timesteps: 22491 Episode Num: 46 Reward: 10.51658531353684\n",
      "Total Timesteps: 22562 Episode Num: 47 Reward: 4.978960281798205\n",
      "Total Timesteps: 22605 Episode Num: 48 Reward: 3.893613671958878\n",
      "Total Timesteps: 23605 Episode Num: 49 Reward: 112.76368086550687\n",
      "Total Timesteps: 23668 Episode Num: 50 Reward: -1.1724578815912707\n",
      "Total Timesteps: 23809 Episode Num: 51 Reward: 18.14616661706862\n",
      "Total Timesteps: 24809 Episode Num: 52 Reward: 193.72813058051725\n",
      "Total Timesteps: 24861 Episode Num: 53 Reward: 0.09534965007616258\n",
      "Total Timesteps: 25861 Episode Num: 54 Reward: 113.29759086780298\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 81.807308\n",
      "---------------------------------------\n",
      "Total Timesteps: 26861 Episode Num: 55 Reward: 114.96022511634759\n",
      "Total Timesteps: 27861 Episode Num: 56 Reward: 183.6346205520597\n",
      "Total Timesteps: 28861 Episode Num: 57 Reward: 183.2354486336454\n",
      "Total Timesteps: 29861 Episode Num: 58 Reward: 109.25085252644523\n",
      "Total Timesteps: 30861 Episode Num: 59 Reward: 156.50945126212508\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 81.456184\n",
      "---------------------------------------\n",
      "Total Timesteps: 31861 Episode Num: 60 Reward: 50.308623668176494\n",
      "Total Timesteps: 32861 Episode Num: 61 Reward: 228.96491563619847\n",
      "Total Timesteps: 33861 Episode Num: 62 Reward: 270.6336174601866\n",
      "Total Timesteps: 34861 Episode Num: 63 Reward: 195.35521638563853\n",
      "Total Timesteps: 35861 Episode Num: 64 Reward: 251.72143611571602\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 239.893618\n",
      "---------------------------------------\n",
      "Total Timesteps: 36861 Episode Num: 65 Reward: 232.7499334107163\n",
      "Total Timesteps: 37861 Episode Num: 66 Reward: 281.4455071999906\n",
      "Total Timesteps: 38861 Episode Num: 67 Reward: 233.57021794878565\n",
      "Total Timesteps: 39861 Episode Num: 68 Reward: 188.47622696856396\n",
      "Total Timesteps: 40861 Episode Num: 69 Reward: 258.5658187828735\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 291.668026\n",
      "---------------------------------------\n",
      "Total Timesteps: 41861 Episode Num: 70 Reward: 378.8651449562014\n",
      "Total Timesteps: 42861 Episode Num: 71 Reward: 187.0997592297446\n",
      "Total Timesteps: 43861 Episode Num: 72 Reward: 251.0735173930922\n",
      "Total Timesteps: 44861 Episode Num: 73 Reward: 381.87265509101684\n",
      "Total Timesteps: 45861 Episode Num: 74 Reward: 303.13196221892014\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 170.005205\n",
      "---------------------------------------\n",
      "Total Timesteps: 46861 Episode Num: 75 Reward: 189.5144445434473\n",
      "Total Timesteps: 47861 Episode Num: 76 Reward: 102.40050659625346\n",
      "Total Timesteps: 48861 Episode Num: 77 Reward: 312.84670220547883\n",
      "Total Timesteps: 49861 Episode Num: 78 Reward: 86.52262293766634\n",
      "Total Timesteps: 50861 Episode Num: 79 Reward: 303.18035314826693\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 247.130744\n",
      "---------------------------------------\n",
      "Total Timesteps: 51861 Episode Num: 80 Reward: 302.21640342059044\n",
      "Total Timesteps: 52861 Episode Num: 81 Reward: 144.48635612768413\n",
      "Total Timesteps: 53861 Episode Num: 82 Reward: 144.35261657748654\n",
      "Total Timesteps: 54861 Episode Num: 83 Reward: 299.3646375311857\n",
      "Total Timesteps: 55861 Episode Num: 84 Reward: 282.6577962514547\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 157.619954\n",
      "---------------------------------------\n",
      "Total Timesteps: 56861 Episode Num: 85 Reward: 192.5957175172857\n",
      "Total Timesteps: 57861 Episode Num: 86 Reward: 171.17161102788106\n",
      "Total Timesteps: 58861 Episode Num: 87 Reward: 213.97459794204337\n",
      "Total Timesteps: 59861 Episode Num: 88 Reward: 135.39049591064332\n",
      "Total Timesteps: 60861 Episode Num: 89 Reward: 324.31325247379124\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 148.106645\n",
      "---------------------------------------\n",
      "Total Timesteps: 61861 Episode Num: 90 Reward: 103.84792892189908\n",
      "Total Timesteps: 62861 Episode Num: 91 Reward: 208.05190305720993\n",
      "Total Timesteps: 63861 Episode Num: 92 Reward: 151.45730746538416\n",
      "Total Timesteps: 64861 Episode Num: 93 Reward: 220.1908230965351\n",
      "Total Timesteps: 65861 Episode Num: 94 Reward: 190.31603561362547\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 86.191907\n",
      "---------------------------------------\n",
      "Total Timesteps: 66861 Episode Num: 95 Reward: 155.55731861580063\n",
      "Total Timesteps: 66881 Episode Num: 96 Reward: 0.8664236810945023\n",
      "Total Timesteps: 67318 Episode Num: 97 Reward: 212.6972516240343\n",
      "Total Timesteps: 68318 Episode Num: 98 Reward: 128.68432066966778\n",
      "Total Timesteps: 69318 Episode Num: 99 Reward: 249.55102052657085\n",
      "Total Timesteps: 70318 Episode Num: 100 Reward: 370.0136697653927\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 312.912734\n",
      "---------------------------------------\n",
      "Total Timesteps: 70533 Episode Num: 101 Reward: 55.27608879483685\n",
      "Total Timesteps: 71533 Episode Num: 102 Reward: 389.31004169272876\n",
      "Total Timesteps: 72533 Episode Num: 103 Reward: 246.34833431024504\n",
      "Total Timesteps: 73533 Episode Num: 104 Reward: 388.05264659262593\n",
      "Total Timesteps: 74533 Episode Num: 105 Reward: 385.8203686664486\n",
      "Total Timesteps: 75533 Episode Num: 106 Reward: 397.5853375182461\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 206.455074\n",
      "---------------------------------------\n",
      "Total Timesteps: 76533 Episode Num: 107 Reward: 289.5880715741656\n",
      "Total Timesteps: 77533 Episode Num: 108 Reward: 399.1512563357738\n",
      "Total Timesteps: 78533 Episode Num: 109 Reward: 203.48896112254587\n",
      "Total Timesteps: 79533 Episode Num: 110 Reward: 181.91752422453524\n",
      "Total Timesteps: 80533 Episode Num: 111 Reward: 322.5438815018416\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 270.894206\n",
      "---------------------------------------\n",
      "Total Timesteps: 81533 Episode Num: 112 Reward: 334.03941787330075\n",
      "Total Timesteps: 82533 Episode Num: 113 Reward: 415.0638050313594\n",
      "Total Timesteps: 83533 Episode Num: 114 Reward: 377.9776795444084\n",
      "Total Timesteps: 84533 Episode Num: 115 Reward: 401.06198210760795\n",
      "Total Timesteps: 84553 Episode Num: 116 Reward: 0.051342431912744235\n",
      "Total Timesteps: 84573 Episode Num: 117 Reward: -0.7257162918690303\n",
      "Total Timesteps: 84593 Episode Num: 118 Reward: -0.9503390904367606\n",
      "Total Timesteps: 84613 Episode Num: 119 Reward: -0.9938346486848237\n",
      "Total Timesteps: 84633 Episode Num: 120 Reward: -0.06408624315948641\n",
      "Total Timesteps: 84653 Episode Num: 121 Reward: -0.5012458422358996\n",
      "Total Timesteps: 84673 Episode Num: 122 Reward: -0.6517187178567205\n",
      "Total Timesteps: 84693 Episode Num: 123 Reward: -1.2423159961212389\n",
      "Total Timesteps: 84713 Episode Num: 124 Reward: -0.5978856944921713\n",
      "Total Timesteps: 84733 Episode Num: 125 Reward: -0.6727501649185741\n",
      "Total Timesteps: 84753 Episode Num: 126 Reward: -0.5280209904027395\n",
      "Total Timesteps: 84773 Episode Num: 127 Reward: -1.9629553647646953\n",
      "Total Timesteps: 84793 Episode Num: 128 Reward: -1.3000745565903666\n",
      "Total Timesteps: 84813 Episode Num: 129 Reward: -0.2619612305355341\n",
      "Total Timesteps: 84833 Episode Num: 130 Reward: -2.105481407575717\n",
      "Total Timesteps: 84853 Episode Num: 131 Reward: -3.0050036251144\n",
      "Total Timesteps: 84986 Episode Num: 132 Reward: 43.85585645034621\n",
      "Total Timesteps: 85986 Episode Num: 133 Reward: 324.308835004342\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 398.544390\n",
      "---------------------------------------\n",
      "Total Timesteps: 86986 Episode Num: 134 Reward: 502.6443896046032\n",
      "Total Timesteps: 87986 Episode Num: 135 Reward: 278.57241901469206\n",
      "Total Timesteps: 88986 Episode Num: 136 Reward: 304.78582656199853\n",
      "Total Timesteps: 89986 Episode Num: 137 Reward: 393.75454394655253\n",
      "Total Timesteps: 90986 Episode Num: 138 Reward: 372.55715975907447\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 258.187314\n",
      "---------------------------------------\n",
      "Total Timesteps: 91986 Episode Num: 139 Reward: 186.144718754996\n",
      "Total Timesteps: 92986 Episode Num: 140 Reward: 364.60345617065377\n",
      "Total Timesteps: 93986 Episode Num: 141 Reward: 266.01675245286236\n",
      "Total Timesteps: 94986 Episode Num: 142 Reward: 178.44768408641133\n",
      "Total Timesteps: 95986 Episode Num: 143 Reward: 204.7663736648011\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 358.252801\n",
      "---------------------------------------\n",
      "Total Timesteps: 96986 Episode Num: 144 Reward: 444.8050387887246\n",
      "Total Timesteps: 97986 Episode Num: 145 Reward: 269.5481412055694\n",
      "Total Timesteps: 98986 Episode Num: 146 Reward: 346.0836949138376\n",
      "Total Timesteps: 99986 Episode Num: 147 Reward: 389.25281332263523\n",
      "Total Timesteps: 100020 Episode Num: 148 Reward: 0.6361521960150482\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 327.631275\n",
      "---------------------------------------\n",
      "Total Timesteps: 100234 Episode Num: 149 Reward: 87.97115569029681\n",
      "Total Timesteps: 101234 Episode Num: 150 Reward: 389.8223823608133\n",
      "Total Timesteps: 102234 Episode Num: 151 Reward: 289.81032866953484\n",
      "Total Timesteps: 103234 Episode Num: 152 Reward: 482.50263329679626\n",
      "Total Timesteps: 104234 Episode Num: 153 Reward: 443.716165554296\n",
      "Total Timesteps: 105234 Episode Num: 154 Reward: 312.070438617403\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 297.254526\n",
      "---------------------------------------\n",
      "Total Timesteps: 106234 Episode Num: 155 Reward: 219.0365726366564\n",
      "Total Timesteps: 107234 Episode Num: 156 Reward: 295.35864076319064\n",
      "Total Timesteps: 108234 Episode Num: 157 Reward: 246.63305085013454\n",
      "Total Timesteps: 109234 Episode Num: 158 Reward: 461.2966607254098\n",
      "Total Timesteps: 110234 Episode Num: 159 Reward: 424.47776411592287\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 422.397243\n",
      "---------------------------------------\n",
      "Total Timesteps: 111234 Episode Num: 160 Reward: 416.178733523839\n",
      "Total Timesteps: 111640 Episode Num: 161 Reward: 99.74959454631987\n",
      "Total Timesteps: 112640 Episode Num: 162 Reward: 495.233230090888\n",
      "Total Timesteps: 113640 Episode Num: 163 Reward: 410.18655232697665\n",
      "Total Timesteps: 114295 Episode Num: 164 Reward: 152.7363152125326\n",
      "Total Timesteps: 114890 Episode Num: 165 Reward: 216.5400552239845\n",
      "Total Timesteps: 115890 Episode Num: 166 Reward: 284.23092092211806\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 243.200049\n",
      "---------------------------------------\n",
      "Total Timesteps: 116890 Episode Num: 167 Reward: 308.0150674341983\n",
      "Total Timesteps: 117890 Episode Num: 168 Reward: 400.10992370801506\n",
      "Total Timesteps: 118890 Episode Num: 169 Reward: 176.88252322549175\n",
      "Total Timesteps: 119022 Episode Num: 170 Reward: 69.85165854519981\n",
      "Total Timesteps: 119084 Episode Num: 171 Reward: 27.398223136882265\n",
      "Total Timesteps: 120084 Episode Num: 172 Reward: 225.36275906770138\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 264.950508\n",
      "---------------------------------------\n",
      "Total Timesteps: 121084 Episode Num: 173 Reward: 340.0755840459148\n",
      "Total Timesteps: 121193 Episode Num: 174 Reward: 59.54225080740531\n",
      "Total Timesteps: 122193 Episode Num: 175 Reward: 319.3611345290334\n",
      "Total Timesteps: 123193 Episode Num: 176 Reward: 235.90400106840485\n",
      "Total Timesteps: 124193 Episode Num: 177 Reward: 198.41775860491794\n",
      "Total Timesteps: 125193 Episode Num: 178 Reward: 233.56988557872478\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 238.397897\n",
      "---------------------------------------\n",
      "Total Timesteps: 126193 Episode Num: 179 Reward: 480.32726674437237\n",
      "Total Timesteps: 127193 Episode Num: 180 Reward: 186.71629702892534\n",
      "Total Timesteps: 128193 Episode Num: 181 Reward: 213.51318040371862\n",
      "Total Timesteps: 129193 Episode Num: 182 Reward: 304.9330058878664\n",
      "Total Timesteps: 130193 Episode Num: 183 Reward: 222.01408647210826\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 136.203821\n",
      "---------------------------------------\n",
      "Total Timesteps: 131193 Episode Num: 184 Reward: 121.83313492475627\n",
      "Total Timesteps: 132193 Episode Num: 185 Reward: 187.16542596106072\n",
      "Total Timesteps: 133193 Episode Num: 186 Reward: 314.3715853655\n",
      "Total Timesteps: 134193 Episode Num: 187 Reward: 246.7849480337671\n",
      "Total Timesteps: 135193 Episode Num: 188 Reward: 283.9674308193817\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 122.612880\n",
      "---------------------------------------\n",
      "Total Timesteps: 136193 Episode Num: 189 Reward: 195.62761766580516\n",
      "Total Timesteps: 137193 Episode Num: 190 Reward: 245.05783028207068\n",
      "Total Timesteps: 138193 Episode Num: 191 Reward: 294.69411043690775\n",
      "Total Timesteps: 138378 Episode Num: 192 Reward: 29.940384994454682\n",
      "Total Timesteps: 139378 Episode Num: 193 Reward: 281.30681438935693\n",
      "Total Timesteps: 139573 Episode Num: 194 Reward: 30.169986968035193\n",
      "Total Timesteps: 140573 Episode Num: 195 Reward: 404.81118215753435\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 259.506946\n",
      "---------------------------------------\n",
      "Total Timesteps: 141573 Episode Num: 196 Reward: 304.40237363483686\n",
      "Total Timesteps: 142573 Episode Num: 197 Reward: 350.3616287527883\n",
      "Total Timesteps: 143573 Episode Num: 198 Reward: 215.337408633575\n",
      "Total Timesteps: 144573 Episode Num: 199 Reward: 265.29192673660145\n",
      "Total Timesteps: 145573 Episode Num: 200 Reward: 328.9310658333224\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 281.453272\n",
      "---------------------------------------\n",
      "Total Timesteps: 146573 Episode Num: 201 Reward: 407.81880171291533\n",
      "Total Timesteps: 147485 Episode Num: 202 Reward: 265.5735728872153\n",
      "Total Timesteps: 148485 Episode Num: 203 Reward: 345.1612125153758\n",
      "Total Timesteps: 149485 Episode Num: 204 Reward: 207.1383418263662\n",
      "Total Timesteps: 150485 Episode Num: 205 Reward: 491.48330652441393\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 397.453745\n",
      "---------------------------------------\n",
      "Total Timesteps: 151485 Episode Num: 206 Reward: 498.4471963464833\n",
      "Total Timesteps: 151699 Episode Num: 207 Reward: 39.673602648715594\n",
      "Total Timesteps: 152699 Episode Num: 208 Reward: 240.6576992693784\n",
      "Total Timesteps: 153699 Episode Num: 209 Reward: 407.56324561123273\n",
      "Total Timesteps: 154420 Episode Num: 210 Reward: 112.33804771935355\n",
      "Total Timesteps: 155420 Episode Num: 211 Reward: 206.41988381873114\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 295.939064\n",
      "---------------------------------------\n",
      "Total Timesteps: 156420 Episode Num: 212 Reward: 455.9352628099311\n",
      "Total Timesteps: 157420 Episode Num: 213 Reward: 440.6727998160159\n",
      "Total Timesteps: 157458 Episode Num: 214 Reward: 16.49305033590752\n",
      "Total Timesteps: 158458 Episode Num: 215 Reward: 116.65551812778277\n",
      "Total Timesteps: 158575 Episode Num: 216 Reward: 63.88171027948958\n",
      "Total Timesteps: 159575 Episode Num: 217 Reward: 307.83340615735443\n",
      "Total Timesteps: 160575 Episode Num: 218 Reward: 512.9723961756981\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 449.613861\n",
      "---------------------------------------\n",
      "Total Timesteps: 161575 Episode Num: 219 Reward: 307.9678135479505\n",
      "Total Timesteps: 162575 Episode Num: 220 Reward: 516.485339422124\n",
      "Total Timesteps: 163575 Episode Num: 221 Reward: 335.97401332427387\n",
      "Total Timesteps: 164575 Episode Num: 222 Reward: 454.46729639087135\n",
      "Total Timesteps: 165575 Episode Num: 223 Reward: 540.8413066898647\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 465.713379\n",
      "---------------------------------------\n",
      "Total Timesteps: 166575 Episode Num: 224 Reward: 261.25853734775563\n",
      "Total Timesteps: 167575 Episode Num: 225 Reward: 377.3512761046625\n",
      "Total Timesteps: 168575 Episode Num: 226 Reward: 335.08652464375444\n",
      "Total Timesteps: 169575 Episode Num: 227 Reward: 449.9038082823333\n",
      "Total Timesteps: 170575 Episode Num: 228 Reward: 338.52989533305004\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 411.213929\n",
      "---------------------------------------\n",
      "Total Timesteps: 171575 Episode Num: 229 Reward: 429.6231957219454\n",
      "Total Timesteps: 172575 Episode Num: 230 Reward: 354.6028136031264\n",
      "Total Timesteps: 173575 Episode Num: 231 Reward: 526.4677295800444\n",
      "Total Timesteps: 174575 Episode Num: 232 Reward: 365.02262484912995\n",
      "Total Timesteps: 175072 Episode Num: 233 Reward: 131.09418322595505\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 195.880585\n",
      "---------------------------------------\n",
      "Total Timesteps: 176072 Episode Num: 234 Reward: 485.6015310097871\n",
      "Total Timesteps: 177072 Episode Num: 235 Reward: 195.87260910956354\n",
      "Total Timesteps: 178072 Episode Num: 236 Reward: 389.9058955108238\n",
      "Total Timesteps: 179072 Episode Num: 237 Reward: 265.38830953569806\n",
      "Total Timesteps: 180072 Episode Num: 238 Reward: 339.36938627781024\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 178.840739\n",
      "---------------------------------------\n",
      "Total Timesteps: 181072 Episode Num: 239 Reward: 122.21391266949881\n",
      "Total Timesteps: 182072 Episode Num: 240 Reward: 153.77870399770237\n",
      "Total Timesteps: 183072 Episode Num: 241 Reward: 201.12820227112348\n",
      "Total Timesteps: 184072 Episode Num: 242 Reward: 244.09007628150684\n",
      "Total Timesteps: 185072 Episode Num: 243 Reward: 512.7243197071995\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 390.722014\n",
      "---------------------------------------\n",
      "Total Timesteps: 186072 Episode Num: 244 Reward: 511.79371611054256\n",
      "Total Timesteps: 187072 Episode Num: 245 Reward: 244.0578152365715\n",
      "Total Timesteps: 188072 Episode Num: 246 Reward: 326.74415974007803\n",
      "Total Timesteps: 189072 Episode Num: 247 Reward: 222.00603664839232\n",
      "Total Timesteps: 189174 Episode Num: 248 Reward: 41.38815625411116\n",
      "Total Timesteps: 190174 Episode Num: 249 Reward: 326.71964850384416\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 312.744066\n",
      "---------------------------------------\n",
      "Total Timesteps: 190787 Episode Num: 250 Reward: 281.40460930414486\n",
      "Total Timesteps: 191787 Episode Num: 251 Reward: 415.3152523592904\n",
      "Total Timesteps: 192787 Episode Num: 252 Reward: 435.0867904115647\n",
      "Total Timesteps: 193017 Episode Num: 253 Reward: 83.75204218780974\n",
      "Total Timesteps: 194017 Episode Num: 254 Reward: 371.0887274829916\n",
      "Total Timesteps: 195017 Episode Num: 255 Reward: 361.7210182861037\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 344.954057\n",
      "---------------------------------------\n",
      "Total Timesteps: 195445 Episode Num: 256 Reward: 192.53188829888217\n",
      "Total Timesteps: 196445 Episode Num: 257 Reward: 490.3035296984747\n",
      "Total Timesteps: 196978 Episode Num: 258 Reward: 255.359143289942\n",
      "Total Timesteps: 197978 Episode Num: 259 Reward: 353.9498905908941\n",
      "Total Timesteps: 198978 Episode Num: 260 Reward: 359.22376954724024\n",
      "Total Timesteps: 199978 Episode Num: 261 Reward: 418.3211628827589\n",
      "Total Timesteps: 200978 Episode Num: 262 Reward: 385.6864987243239\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 377.949714\n",
      "---------------------------------------\n",
      "Total Timesteps: 201978 Episode Num: 263 Reward: 231.71155661657187\n",
      "Total Timesteps: 202978 Episode Num: 264 Reward: 545.9470920346776\n",
      "Total Timesteps: 203978 Episode Num: 265 Reward: 247.41100075678148\n",
      "Total Timesteps: 204978 Episode Num: 266 Reward: 317.11769302746944\n",
      "Total Timesteps: 205978 Episode Num: 267 Reward: 265.9342894722416\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 344.136731\n",
      "---------------------------------------\n",
      "Total Timesteps: 206978 Episode Num: 268 Reward: 497.80104479211127\n",
      "Total Timesteps: 207978 Episode Num: 269 Reward: 227.44398337986738\n",
      "Total Timesteps: 208978 Episode Num: 270 Reward: 204.69780888721138\n",
      "Total Timesteps: 209978 Episode Num: 271 Reward: 251.92544720472864\n",
      "Total Timesteps: 210978 Episode Num: 272 Reward: 539.6799177545269\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 304.655567\n",
      "---------------------------------------\n",
      "Total Timesteps: 211978 Episode Num: 273 Reward: 177.2990003138261\n",
      "Total Timesteps: 212978 Episode Num: 274 Reward: 450.30808621417174\n",
      "Total Timesteps: 213978 Episode Num: 275 Reward: 447.9830939013081\n",
      "Total Timesteps: 214978 Episode Num: 276 Reward: 386.02379150590053\n",
      "Total Timesteps: 215978 Episode Num: 277 Reward: 478.4341975901605\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 331.778247\n",
      "---------------------------------------\n",
      "Total Timesteps: 216978 Episode Num: 278 Reward: 220.1985460806849\n",
      "Total Timesteps: 217978 Episode Num: 279 Reward: 596.107887935326\n",
      "Total Timesteps: 218978 Episode Num: 280 Reward: 639.3676430634221\n",
      "Total Timesteps: 219978 Episode Num: 281 Reward: 364.4614384572005\n",
      "Total Timesteps: 220978 Episode Num: 282 Reward: 379.0173818020206\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 408.307611\n",
      "---------------------------------------\n",
      "Total Timesteps: 221978 Episode Num: 283 Reward: 402.99588093319466\n",
      "Total Timesteps: 222978 Episode Num: 284 Reward: 388.955930280014\n",
      "Total Timesteps: 223978 Episode Num: 285 Reward: 483.38501622556834\n",
      "Total Timesteps: 224978 Episode Num: 286 Reward: 423.85006916440113\n",
      "Total Timesteps: 225978 Episode Num: 287 Reward: 442.2888048577038\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 400.474727\n",
      "---------------------------------------\n",
      "Total Timesteps: 226978 Episode Num: 288 Reward: 516.6736486719093\n",
      "Total Timesteps: 227978 Episode Num: 289 Reward: 453.0432379020251\n",
      "Total Timesteps: 228978 Episode Num: 290 Reward: 625.132179186216\n",
      "Total Timesteps: 229978 Episode Num: 291 Reward: 131.35055298178432\n",
      "Total Timesteps: 230978 Episode Num: 292 Reward: 482.0931269064851\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 487.839083\n",
      "---------------------------------------\n",
      "Total Timesteps: 231800 Episode Num: 293 Reward: 492.9279009896089\n",
      "Total Timesteps: 232800 Episode Num: 294 Reward: 404.9933385217965\n",
      "Total Timesteps: 233800 Episode Num: 295 Reward: 486.4791180808808\n",
      "Total Timesteps: 234800 Episode Num: 296 Reward: 441.2539083275807\n",
      "Total Timesteps: 235800 Episode Num: 297 Reward: 206.75360662267605\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 495.750486\n",
      "---------------------------------------\n",
      "Total Timesteps: 236800 Episode Num: 298 Reward: 602.3943110291988\n",
      "Total Timesteps: 237800 Episode Num: 299 Reward: 434.3441885579713\n",
      "Total Timesteps: 238800 Episode Num: 300 Reward: 473.3194799906718\n",
      "Total Timesteps: 239800 Episode Num: 301 Reward: 546.3633611962251\n",
      "Total Timesteps: 240800 Episode Num: 302 Reward: 389.82723030146906\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 447.755749\n",
      "---------------------------------------\n",
      "Total Timesteps: 241800 Episode Num: 303 Reward: 548.2700714873241\n",
      "Total Timesteps: 242800 Episode Num: 304 Reward: 224.7418158320822\n",
      "Total Timesteps: 243800 Episode Num: 305 Reward: 219.29525277129545\n",
      "Total Timesteps: 244800 Episode Num: 306 Reward: 299.9780433572193\n",
      "Total Timesteps: 245800 Episode Num: 307 Reward: 332.42608978889785\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 359.858960\n",
      "---------------------------------------\n",
      "Total Timesteps: 246800 Episode Num: 308 Reward: 291.3979791399131\n",
      "Total Timesteps: 247800 Episode Num: 309 Reward: 302.4720324697813\n",
      "Total Timesteps: 248800 Episode Num: 310 Reward: 369.3600716996245\n",
      "Total Timesteps: 249800 Episode Num: 311 Reward: 320.1693439540933\n",
      "Total Timesteps: 250004 Episode Num: 312 Reward: 34.92847795370892\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 217.318850\n",
      "---------------------------------------\n",
      "Total Timesteps: 251004 Episode Num: 313 Reward: 322.38043100603625\n",
      "Total Timesteps: 252004 Episode Num: 314 Reward: 403.47916177211835\n",
      "Total Timesteps: 253004 Episode Num: 315 Reward: 205.96940855293298\n",
      "Total Timesteps: 253416 Episode Num: 316 Reward: 81.69820279139101\n",
      "Total Timesteps: 254416 Episode Num: 317 Reward: 253.26021952198732\n",
      "Total Timesteps: 255416 Episode Num: 318 Reward: 283.55814340272264\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 307.174816\n",
      "---------------------------------------\n",
      "Total Timesteps: 255751 Episode Num: 319 Reward: 73.9012355472693\n",
      "Total Timesteps: 256751 Episode Num: 320 Reward: 342.5880120361457\n",
      "Total Timesteps: 257751 Episode Num: 321 Reward: 203.48370877557693\n",
      "Total Timesteps: 257815 Episode Num: 322 Reward: 1.0119377093905766\n",
      "Total Timesteps: 258815 Episode Num: 323 Reward: 356.26726819742845\n",
      "Total Timesteps: 259815 Episode Num: 324 Reward: 319.3784442443587\n",
      "Total Timesteps: 259956 Episode Num: 325 Reward: 21.62991805221546\n",
      "Total Timesteps: 260956 Episode Num: 326 Reward: 429.5076705604205\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 178.219350\n",
      "---------------------------------------\n",
      "Total Timesteps: 261956 Episode Num: 327 Reward: 381.7760291412587\n",
      "Total Timesteps: 262298 Episode Num: 328 Reward: 136.1117294700594\n",
      "Total Timesteps: 262669 Episode Num: 329 Reward: 88.81744330655833\n",
      "Total Timesteps: 262791 Episode Num: 330 Reward: 27.140589424609626\n",
      "Total Timesteps: 262899 Episode Num: 331 Reward: 16.7047138790902\n",
      "Total Timesteps: 263038 Episode Num: 332 Reward: 21.29728484892169\n",
      "Total Timesteps: 263287 Episode Num: 333 Reward: 70.1609038398653\n",
      "Total Timesteps: 263527 Episode Num: 334 Reward: 57.77991295323834\n",
      "Total Timesteps: 263790 Episode Num: 335 Reward: 46.94389990952248\n",
      "Total Timesteps: 264051 Episode Num: 336 Reward: 52.14199996356914\n",
      "Total Timesteps: 264485 Episode Num: 337 Reward: 74.48129401991127\n",
      "Total Timesteps: 265485 Episode Num: 338 Reward: 412.3790828927916\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 161.628219\n",
      "---------------------------------------\n",
      "Total Timesteps: 266485 Episode Num: 339 Reward: 143.98653951104856\n",
      "Total Timesteps: 267485 Episode Num: 340 Reward: 219.72932428646357\n",
      "Total Timesteps: 268485 Episode Num: 341 Reward: 140.5497226860038\n",
      "Total Timesteps: 269485 Episode Num: 342 Reward: 215.9784699783085\n",
      "Total Timesteps: 270485 Episode Num: 343 Reward: 269.95960059169454\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 185.979471\n",
      "---------------------------------------\n",
      "Total Timesteps: 271485 Episode Num: 344 Reward: 176.7677240756247\n",
      "Total Timesteps: 272485 Episode Num: 345 Reward: 85.93707593330687\n",
      "Total Timesteps: 273485 Episode Num: 346 Reward: 100.6030890304762\n",
      "Total Timesteps: 274485 Episode Num: 347 Reward: 195.9930468382427\n",
      "Total Timesteps: 275485 Episode Num: 348 Reward: 210.6832532151511\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 315.894327\n",
      "---------------------------------------\n",
      "Total Timesteps: 276485 Episode Num: 349 Reward: 484.57734145754665\n",
      "Total Timesteps: 277485 Episode Num: 350 Reward: 359.74038554703213\n",
      "Total Timesteps: 278485 Episode Num: 351 Reward: 329.6050939076184\n",
      "Total Timesteps: 279485 Episode Num: 352 Reward: 533.124008804811\n",
      "Total Timesteps: 280485 Episode Num: 353 Reward: 646.6329980768026\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 491.090864\n",
      "---------------------------------------\n",
      "Total Timesteps: 281485 Episode Num: 354 Reward: 470.0795656476703\n",
      "Total Timesteps: 282485 Episode Num: 355 Reward: 586.0924580166353\n",
      "Total Timesteps: 283485 Episode Num: 356 Reward: 311.8434517069026\n",
      "Total Timesteps: 284485 Episode Num: 357 Reward: 488.4150131515794\n",
      "Total Timesteps: 285485 Episode Num: 358 Reward: 426.41505168939847\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 503.382704\n",
      "---------------------------------------\n",
      "Total Timesteps: 286485 Episode Num: 359 Reward: 431.8055489225314\n",
      "Total Timesteps: 287485 Episode Num: 360 Reward: 670.7688095535344\n",
      "Total Timesteps: 288485 Episode Num: 361 Reward: 601.8392561693138\n",
      "Total Timesteps: 289485 Episode Num: 362 Reward: 507.7189142039108\n",
      "Total Timesteps: 290485 Episode Num: 363 Reward: 577.0002683031859\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 464.167121\n",
      "---------------------------------------\n",
      "Total Timesteps: 291485 Episode Num: 364 Reward: 493.18795159851595\n",
      "Total Timesteps: 292485 Episode Num: 365 Reward: 621.486810672226\n",
      "Total Timesteps: 293485 Episode Num: 366 Reward: 419.0809260467284\n",
      "Total Timesteps: 294485 Episode Num: 367 Reward: 619.3006094456086\n",
      "Total Timesteps: 295485 Episode Num: 368 Reward: 604.888233764451\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 450.622795\n",
      "---------------------------------------\n",
      "Total Timesteps: 296485 Episode Num: 369 Reward: 413.8896362518411\n",
      "Total Timesteps: 297485 Episode Num: 370 Reward: 600.5344307005116\n",
      "Total Timesteps: 298485 Episode Num: 371 Reward: 406.6396422544286\n",
      "Total Timesteps: 299485 Episode Num: 372 Reward: 522.8514253120386\n",
      "Total Timesteps: 300485 Episode Num: 373 Reward: 450.79135372586853\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 460.521258\n",
      "---------------------------------------\n",
      "Total Timesteps: 301485 Episode Num: 374 Reward: 351.1735781313728\n",
      "Total Timesteps: 302485 Episode Num: 375 Reward: 353.66952076506476\n",
      "Total Timesteps: 303485 Episode Num: 376 Reward: 720.1193262770466\n",
      "Total Timesteps: 304485 Episode Num: 377 Reward: 632.8213423175902\n",
      "Total Timesteps: 305485 Episode Num: 378 Reward: 312.90517712581544\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 355.652775\n",
      "---------------------------------------\n",
      "Total Timesteps: 306485 Episode Num: 379 Reward: 797.0440400196308\n",
      "Total Timesteps: 307485 Episode Num: 380 Reward: 445.97966000628804\n",
      "Total Timesteps: 308485 Episode Num: 381 Reward: 428.7931247292415\n",
      "Total Timesteps: 309485 Episode Num: 382 Reward: 703.3593973677655\n",
      "Total Timesteps: 310485 Episode Num: 383 Reward: 626.6974926110612\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 463.788172\n",
      "---------------------------------------\n",
      "Total Timesteps: 311485 Episode Num: 384 Reward: 721.5009994376968\n",
      "Total Timesteps: 312485 Episode Num: 385 Reward: 463.24796336983565\n",
      "Total Timesteps: 313485 Episode Num: 386 Reward: 363.96244395225125\n",
      "Total Timesteps: 314485 Episode Num: 387 Reward: 311.576029644358\n",
      "Total Timesteps: 315485 Episode Num: 388 Reward: 311.01932649959184\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 457.588920\n",
      "---------------------------------------\n",
      "Total Timesteps: 316485 Episode Num: 389 Reward: 614.2915399550782\n",
      "Total Timesteps: 317485 Episode Num: 390 Reward: 415.59258621403177\n",
      "Total Timesteps: 318485 Episode Num: 391 Reward: 391.8893695797914\n",
      "Total Timesteps: 319485 Episode Num: 392 Reward: 578.2053344083531\n",
      "Total Timesteps: 320485 Episode Num: 393 Reward: 247.2829844959918\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 295.816750\n",
      "---------------------------------------\n",
      "Total Timesteps: 321485 Episode Num: 394 Reward: 496.61446866175044\n",
      "Total Timesteps: 322485 Episode Num: 395 Reward: 495.7847608723202\n",
      "Total Timesteps: 323485 Episode Num: 396 Reward: 628.5689349399395\n",
      "Total Timesteps: 324485 Episode Num: 397 Reward: 482.32854220609744\n",
      "Total Timesteps: 325485 Episode Num: 398 Reward: 629.7960119708524\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 356.280037\n",
      "---------------------------------------\n",
      "Total Timesteps: 326485 Episode Num: 399 Reward: 276.556128262915\n",
      "Total Timesteps: 327485 Episode Num: 400 Reward: 664.252185388071\n",
      "Total Timesteps: 328485 Episode Num: 401 Reward: 450.05019924454086\n",
      "Total Timesteps: 329485 Episode Num: 402 Reward: 453.0179084614804\n",
      "Total Timesteps: 330485 Episode Num: 403 Reward: 389.8875083621278\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 241.295072\n",
      "---------------------------------------\n",
      "Total Timesteps: 331485 Episode Num: 404 Reward: 186.58158564976029\n",
      "Total Timesteps: 332485 Episode Num: 405 Reward: 391.4010045210866\n",
      "Total Timesteps: 333485 Episode Num: 406 Reward: 116.1489379253094\n",
      "Total Timesteps: 334485 Episode Num: 407 Reward: 192.0718763599822\n",
      "Total Timesteps: 335485 Episode Num: 408 Reward: 300.15831812136594\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 473.725921\n",
      "---------------------------------------\n",
      "Total Timesteps: 336485 Episode Num: 409 Reward: 580.7734736651322\n",
      "Total Timesteps: 337485 Episode Num: 410 Reward: 484.074971616535\n",
      "Total Timesteps: 338485 Episode Num: 411 Reward: 345.6162824991705\n",
      "Total Timesteps: 339485 Episode Num: 412 Reward: 251.8007012908989\n",
      "Total Timesteps: 339618 Episode Num: 413 Reward: 2.2837722248989625\n",
      "Total Timesteps: 340618 Episode Num: 414 Reward: 326.94885021345334\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 298.210496\n",
      "---------------------------------------\n",
      "Total Timesteps: 341618 Episode Num: 415 Reward: 286.7187399342418\n",
      "Total Timesteps: 342618 Episode Num: 416 Reward: 670.0746016675913\n",
      "Total Timesteps: 343618 Episode Num: 417 Reward: 610.1934791147859\n",
      "Total Timesteps: 344618 Episode Num: 418 Reward: 478.16350930173974\n",
      "Total Timesteps: 345618 Episode Num: 419 Reward: 468.7431594715843\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 369.729078\n",
      "---------------------------------------\n",
      "Total Timesteps: 346618 Episode Num: 420 Reward: 492.1632925648432\n",
      "Total Timesteps: 347618 Episode Num: 421 Reward: 423.5777644496374\n",
      "Total Timesteps: 348618 Episode Num: 422 Reward: 465.46413810832405\n",
      "Total Timesteps: 348740 Episode Num: 423 Reward: 17.17995451406887\n",
      "Total Timesteps: 349740 Episode Num: 424 Reward: 342.63915404677164\n",
      "Total Timesteps: 350740 Episode Num: 425 Reward: 597.1509584666325\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 366.230265\n",
      "---------------------------------------\n",
      "Total Timesteps: 351740 Episode Num: 426 Reward: 601.2331403287669\n",
      "Total Timesteps: 352740 Episode Num: 427 Reward: 358.3703631233625\n",
      "Total Timesteps: 353740 Episode Num: 428 Reward: 415.51097621309185\n",
      "Total Timesteps: 354740 Episode Num: 429 Reward: 425.39260605675787\n",
      "Total Timesteps: 354874 Episode Num: 430 Reward: 57.76449173954114\n",
      "Total Timesteps: 355874 Episode Num: 431 Reward: 347.4130083358985\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 437.091846\n",
      "---------------------------------------\n",
      "Total Timesteps: 356874 Episode Num: 432 Reward: 440.969380230139\n",
      "Total Timesteps: 357874 Episode Num: 433 Reward: 287.3828388589978\n",
      "Total Timesteps: 358874 Episode Num: 434 Reward: 438.946848259512\n",
      "Total Timesteps: 359874 Episode Num: 435 Reward: 524.5914641122794\n",
      "Total Timesteps: 360874 Episode Num: 436 Reward: 320.20346571460317\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 417.795907\n",
      "---------------------------------------\n",
      "Total Timesteps: 361874 Episode Num: 437 Reward: 417.45784436174495\n",
      "Total Timesteps: 362874 Episode Num: 438 Reward: 294.1319716287022\n",
      "Total Timesteps: 363874 Episode Num: 439 Reward: 526.7537441620683\n",
      "Total Timesteps: 364874 Episode Num: 440 Reward: 537.4534972677936\n",
      "Total Timesteps: 365874 Episode Num: 441 Reward: 516.9178153275193\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 394.444440\n",
      "---------------------------------------\n",
      "Total Timesteps: 366874 Episode Num: 442 Reward: 340.7664158636179\n",
      "Total Timesteps: 367874 Episode Num: 443 Reward: 331.49772076777197\n",
      "Total Timesteps: 368874 Episode Num: 444 Reward: 219.79405670959775\n",
      "Total Timesteps: 369874 Episode Num: 445 Reward: 202.40215145830132\n",
      "Total Timesteps: 370874 Episode Num: 446 Reward: 393.9060088252356\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 355.241860\n",
      "---------------------------------------\n",
      "Total Timesteps: 371874 Episode Num: 447 Reward: 574.219496574359\n",
      "Total Timesteps: 372874 Episode Num: 448 Reward: 411.4446900397132\n",
      "Total Timesteps: 373874 Episode Num: 449 Reward: 268.9084497519139\n",
      "Total Timesteps: 374874 Episode Num: 450 Reward: 234.4584909013441\n",
      "Total Timesteps: 375874 Episode Num: 451 Reward: 458.0358677947548\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 395.516130\n",
      "---------------------------------------\n",
      "Total Timesteps: 376874 Episode Num: 452 Reward: 450.3158944938654\n",
      "Total Timesteps: 377874 Episode Num: 453 Reward: 609.5714368140996\n",
      "Total Timesteps: 378874 Episode Num: 454 Reward: 355.8704710245334\n",
      "Total Timesteps: 379874 Episode Num: 455 Reward: 304.8933859470315\n",
      "Total Timesteps: 380874 Episode Num: 456 Reward: 215.2934704020193\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 399.931728\n",
      "---------------------------------------\n",
      "Total Timesteps: 381874 Episode Num: 457 Reward: 325.0598146419062\n",
      "Total Timesteps: 382874 Episode Num: 458 Reward: 218.10075977241334\n",
      "Total Timesteps: 383874 Episode Num: 459 Reward: 451.7886907203303\n",
      "Total Timesteps: 384874 Episode Num: 460 Reward: 441.6847259093293\n",
      "Total Timesteps: 385874 Episode Num: 461 Reward: 355.44122897054393\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 300.144554\n",
      "---------------------------------------\n",
      "Total Timesteps: 386874 Episode Num: 462 Reward: 235.87825812790354\n",
      "Total Timesteps: 387874 Episode Num: 463 Reward: 313.7043050828799\n",
      "Total Timesteps: 388874 Episode Num: 464 Reward: 417.57398793282476\n",
      "Total Timesteps: 389874 Episode Num: 465 Reward: 344.453815426265\n",
      "Total Timesteps: 390874 Episode Num: 466 Reward: 488.90342880806037\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 504.468737\n",
      "---------------------------------------\n",
      "Total Timesteps: 391874 Episode Num: 467 Reward: 536.8073465178528\n",
      "Total Timesteps: 392874 Episode Num: 468 Reward: 618.6575746276882\n",
      "Total Timesteps: 393874 Episode Num: 469 Reward: 678.0219398138726\n",
      "Total Timesteps: 394874 Episode Num: 470 Reward: 651.1067614384898\n",
      "Total Timesteps: 395874 Episode Num: 471 Reward: 457.6924529073684\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 464.401706\n",
      "---------------------------------------\n",
      "Total Timesteps: 396874 Episode Num: 472 Reward: 725.2744593765134\n",
      "Total Timesteps: 397874 Episode Num: 473 Reward: 342.94115192685865\n",
      "Total Timesteps: 398874 Episode Num: 474 Reward: 496.5213664653083\n",
      "Total Timesteps: 399874 Episode Num: 475 Reward: 482.1815930734709\n",
      "Total Timesteps: 400874 Episode Num: 476 Reward: 585.4893878816538\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 325.086576\n",
      "---------------------------------------\n",
      "Total Timesteps: 401874 Episode Num: 477 Reward: 252.56740963266512\n",
      "Total Timesteps: 402874 Episode Num: 478 Reward: 424.6473198206053\n",
      "Total Timesteps: 403874 Episode Num: 479 Reward: 249.80133819721843\n",
      "Total Timesteps: 404874 Episode Num: 480 Reward: 121.17478334896467\n",
      "Total Timesteps: 405874 Episode Num: 481 Reward: 376.05370326830786\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 168.766667\n",
      "---------------------------------------\n",
      "Total Timesteps: 406874 Episode Num: 482 Reward: 208.18958352234728\n",
      "Total Timesteps: 407874 Episode Num: 483 Reward: 292.1997800045232\n",
      "Total Timesteps: 408874 Episode Num: 484 Reward: 97.51510003302599\n",
      "Total Timesteps: 409874 Episode Num: 485 Reward: 378.1643679571398\n",
      "Total Timesteps: 410874 Episode Num: 486 Reward: 551.0060552164512\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 373.299387\n",
      "---------------------------------------\n",
      "Total Timesteps: 411874 Episode Num: 487 Reward: 606.3682646445242\n",
      "Total Timesteps: 412874 Episode Num: 488 Reward: 519.7378959048343\n",
      "Total Timesteps: 413874 Episode Num: 489 Reward: 503.9951652256172\n",
      "Total Timesteps: 414874 Episode Num: 490 Reward: 540.8080101914082\n",
      "Total Timesteps: 415874 Episode Num: 491 Reward: 546.5567673098209\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 495.634720\n",
      "---------------------------------------\n",
      "Total Timesteps: 416874 Episode Num: 492 Reward: 550.3201855824468\n",
      "Total Timesteps: 417874 Episode Num: 493 Reward: 469.3645230023175\n",
      "Total Timesteps: 418874 Episode Num: 494 Reward: 485.23713628301726\n",
      "Total Timesteps: 419874 Episode Num: 495 Reward: 609.0474557334848\n",
      "Total Timesteps: 420874 Episode Num: 496 Reward: 547.1429585257277\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 511.202616\n",
      "---------------------------------------\n",
      "Total Timesteps: 421874 Episode Num: 497 Reward: 453.02397343125864\n",
      "Total Timesteps: 422874 Episode Num: 498 Reward: 423.98630638509536\n",
      "Total Timesteps: 423874 Episode Num: 499 Reward: 394.5293346141127\n",
      "Total Timesteps: 424874 Episode Num: 500 Reward: 478.6347544394428\n",
      "Total Timesteps: 425874 Episode Num: 501 Reward: 534.870209947286\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 462.409362\n",
      "---------------------------------------\n",
      "Total Timesteps: 426874 Episode Num: 502 Reward: 527.9642530813222\n",
      "Total Timesteps: 427216 Episode Num: 503 Reward: 141.51300664753347\n",
      "Total Timesteps: 428216 Episode Num: 504 Reward: 541.1335810906857\n",
      "Total Timesteps: 429216 Episode Num: 505 Reward: 443.6243604221411\n",
      "Total Timesteps: 430216 Episode Num: 506 Reward: 439.66720081066603\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 553.430893\n",
      "---------------------------------------\n",
      "Total Timesteps: 431216 Episode Num: 507 Reward: 547.3033564621938\n",
      "Total Timesteps: 432216 Episode Num: 508 Reward: 507.8720910085084\n",
      "Total Timesteps: 433216 Episode Num: 509 Reward: 541.3379466467541\n",
      "Total Timesteps: 434216 Episode Num: 510 Reward: 525.636402490378\n",
      "Total Timesteps: 435216 Episode Num: 511 Reward: 698.8569438369267\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 539.197949\n",
      "---------------------------------------\n",
      "Total Timesteps: 436216 Episode Num: 512 Reward: 575.639989664535\n",
      "Total Timesteps: 437216 Episode Num: 513 Reward: 459.7654960034284\n",
      "Total Timesteps: 438216 Episode Num: 514 Reward: 645.4061982443193\n",
      "Total Timesteps: 439216 Episode Num: 515 Reward: 527.3520205206627\n",
      "Total Timesteps: 440216 Episode Num: 516 Reward: 358.09087752832704\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 399.623262\n",
      "---------------------------------------\n",
      "Total Timesteps: 440432 Episode Num: 517 Reward: 85.91300617311872\n",
      "Total Timesteps: 441432 Episode Num: 518 Reward: 442.1168191091118\n",
      "Total Timesteps: 442432 Episode Num: 519 Reward: 501.9651770028324\n",
      "Total Timesteps: 443432 Episode Num: 520 Reward: 353.5614165314088\n",
      "Total Timesteps: 444432 Episode Num: 521 Reward: 552.7122363269154\n",
      "Total Timesteps: 445432 Episode Num: 522 Reward: 598.508543720994\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 475.381763\n",
      "---------------------------------------\n",
      "Total Timesteps: 446432 Episode Num: 523 Reward: 595.8991032297649\n",
      "Total Timesteps: 447432 Episode Num: 524 Reward: 447.47854202962225\n",
      "Total Timesteps: 448432 Episode Num: 525 Reward: 600.3330276636945\n",
      "Total Timesteps: 449432 Episode Num: 526 Reward: 342.0994277646221\n",
      "Total Timesteps: 450432 Episode Num: 527 Reward: 436.7644626333515\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 284.097022\n",
      "---------------------------------------\n",
      "Total Timesteps: 451432 Episode Num: 528 Reward: 320.18518379001205\n",
      "Total Timesteps: 452432 Episode Num: 529 Reward: 187.87964300292487\n",
      "Total Timesteps: 453432 Episode Num: 530 Reward: 516.6590303723403\n",
      "Total Timesteps: 454432 Episode Num: 531 Reward: 476.466791264182\n",
      "Total Timesteps: 455432 Episode Num: 532 Reward: 477.78290460341924\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 327.285233\n",
      "---------------------------------------\n",
      "Total Timesteps: 456432 Episode Num: 533 Reward: 505.3452696570407\n",
      "Total Timesteps: 457300 Episode Num: 534 Reward: 338.86161404800356\n",
      "Total Timesteps: 458300 Episode Num: 535 Reward: 202.94225120481468\n",
      "Total Timesteps: 459300 Episode Num: 536 Reward: 541.8138530100307\n",
      "Total Timesteps: 460300 Episode Num: 537 Reward: 209.65772489995263\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 361.060479\n",
      "---------------------------------------\n",
      "Total Timesteps: 461300 Episode Num: 538 Reward: 448.7555794970122\n",
      "Total Timesteps: 461662 Episode Num: 539 Reward: 193.2743718398775\n",
      "Total Timesteps: 462662 Episode Num: 540 Reward: 445.7108567263805\n",
      "Total Timesteps: 463662 Episode Num: 541 Reward: 246.60681340053654\n",
      "Total Timesteps: 464662 Episode Num: 542 Reward: 370.43268413579284\n",
      "Total Timesteps: 465662 Episode Num: 543 Reward: 244.5112011138723\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 392.815713\n",
      "---------------------------------------\n",
      "Total Timesteps: 466662 Episode Num: 544 Reward: 127.00274514432195\n",
      "Total Timesteps: 467662 Episode Num: 545 Reward: 454.5134061114942\n",
      "Total Timesteps: 468662 Episode Num: 546 Reward: 385.48802111536304\n",
      "Total Timesteps: 469662 Episode Num: 547 Reward: 638.590595872393\n",
      "Total Timesteps: 470662 Episode Num: 548 Reward: 418.0589033897166\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 429.212112\n",
      "---------------------------------------\n",
      "Total Timesteps: 471662 Episode Num: 549 Reward: 322.61245063778284\n",
      "Total Timesteps: 472662 Episode Num: 550 Reward: 420.76505048935513\n",
      "Total Timesteps: 473662 Episode Num: 551 Reward: 476.115102204276\n",
      "Total Timesteps: 474662 Episode Num: 552 Reward: 312.4619226138829\n",
      "Total Timesteps: 475662 Episode Num: 553 Reward: 462.5602384892332\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 473.557350\n",
      "---------------------------------------\n",
      "Total Timesteps: 476662 Episode Num: 554 Reward: 548.4539903086923\n",
      "Total Timesteps: 477662 Episode Num: 555 Reward: 666.6609435745232\n",
      "Total Timesteps: 478662 Episode Num: 556 Reward: 506.5884801242228\n",
      "Total Timesteps: 479662 Episode Num: 557 Reward: 218.00279026230714\n",
      "Total Timesteps: 480662 Episode Num: 558 Reward: 388.1014174685528\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 580.017289\n",
      "---------------------------------------\n",
      "Total Timesteps: 481662 Episode Num: 559 Reward: 722.5762747203526\n",
      "Total Timesteps: 482662 Episode Num: 560 Reward: 572.046337444202\n",
      "Total Timesteps: 483662 Episode Num: 561 Reward: 583.037528751257\n",
      "Total Timesteps: 484662 Episode Num: 562 Reward: 545.1905867587103\n",
      "Total Timesteps: 485662 Episode Num: 563 Reward: 597.2755808039977\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 316.176710\n",
      "---------------------------------------\n",
      "Total Timesteps: 486662 Episode Num: 564 Reward: 343.6440010199775\n",
      "Total Timesteps: 487662 Episode Num: 565 Reward: 425.42480420332527\n",
      "Total Timesteps: 488662 Episode Num: 566 Reward: 579.3074502764538\n",
      "Total Timesteps: 489662 Episode Num: 567 Reward: 531.1202551022196\n",
      "Total Timesteps: 490662 Episode Num: 568 Reward: 578.658712895887\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 557.783036\n",
      "---------------------------------------\n",
      "Total Timesteps: 491662 Episode Num: 569 Reward: 522.7508591413722\n",
      "Total Timesteps: 492662 Episode Num: 570 Reward: 505.7515601065364\n",
      "Total Timesteps: 493662 Episode Num: 571 Reward: 492.0758223646911\n",
      "Total Timesteps: 494662 Episode Num: 572 Reward: 593.0455115332662\n",
      "Total Timesteps: 495662 Episode Num: 573 Reward: 492.8382177041479\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 563.892698\n",
      "---------------------------------------\n",
      "Total Timesteps: 496662 Episode Num: 574 Reward: 704.4900375050125\n",
      "Total Timesteps: 497662 Episode Num: 575 Reward: 471.88020627077015\n",
      "Total Timesteps: 498662 Episode Num: 576 Reward: 495.72536451447246\n",
      "Total Timesteps: 499662 Episode Num: 577 Reward: 542.1917569468214\n",
      "Total Timesteps: 500662 Episode Num: 578 Reward: 588.2655939599576\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 561.404366\n",
      "---------------------------------------\n",
      "Total Timesteps: 501662 Episode Num: 579 Reward: 681.9405767901167\n",
      "Total Timesteps: 502662 Episode Num: 580 Reward: 515.5642152778847\n",
      "Total Timesteps: 503662 Episode Num: 581 Reward: 471.48001075497433\n",
      "Total Timesteps: 504662 Episode Num: 582 Reward: 662.1394207536305\n",
      "Total Timesteps: 505662 Episode Num: 583 Reward: 538.0980157284803\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 617.992153\n",
      "---------------------------------------\n",
      "Total Timesteps: 506662 Episode Num: 584 Reward: 562.9127940241513\n",
      "Total Timesteps: 507662 Episode Num: 585 Reward: 618.3400088242996\n",
      "Total Timesteps: 508662 Episode Num: 586 Reward: 626.0233164588731\n",
      "Total Timesteps: 509662 Episode Num: 587 Reward: 625.8515452251949\n",
      "Total Timesteps: 510662 Episode Num: 588 Reward: 490.28421767895236\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 609.198976\n",
      "---------------------------------------\n",
      "Total Timesteps: 511662 Episode Num: 589 Reward: 703.7198459364087\n",
      "Total Timesteps: 512662 Episode Num: 590 Reward: 573.8030843608958\n",
      "Total Timesteps: 513662 Episode Num: 591 Reward: 611.476669302083\n",
      "Total Timesteps: 514662 Episode Num: 592 Reward: 666.7670528806007\n",
      "Total Timesteps: 515662 Episode Num: 593 Reward: 545.1821622485971\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 594.737807\n",
      "---------------------------------------\n",
      "Total Timesteps: 516662 Episode Num: 594 Reward: 467.7533198390745\n",
      "Total Timesteps: 517662 Episode Num: 595 Reward: 427.0314838480487\n",
      "Total Timesteps: 518662 Episode Num: 596 Reward: 642.2528733091576\n",
      "Total Timesteps: 519662 Episode Num: 597 Reward: 543.7909148297284\n",
      "Total Timesteps: 520662 Episode Num: 598 Reward: 604.8703725186128\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 644.781155\n",
      "---------------------------------------\n",
      "Total Timesteps: 521662 Episode Num: 599 Reward: 527.9331480918121\n",
      "Total Timesteps: 522662 Episode Num: 600 Reward: 514.3593261480412\n",
      "Total Timesteps: 523662 Episode Num: 601 Reward: 699.8241711071884\n",
      "Total Timesteps: 524662 Episode Num: 602 Reward: 767.2086266601789\n",
      "Total Timesteps: 525662 Episode Num: 603 Reward: 563.0741888214909\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 566.764672\n",
      "---------------------------------------\n",
      "Total Timesteps: 526662 Episode Num: 604 Reward: 663.2466724779409\n",
      "Total Timesteps: 527662 Episode Num: 605 Reward: 404.5992319205635\n",
      "Total Timesteps: 528662 Episode Num: 606 Reward: 625.7969116952223\n",
      "Total Timesteps: 529662 Episode Num: 607 Reward: 444.0422214925261\n",
      "Total Timesteps: 530662 Episode Num: 608 Reward: 553.5559676077363\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 504.453909\n",
      "---------------------------------------\n",
      "Total Timesteps: 531662 Episode Num: 609 Reward: 375.5536956210755\n",
      "Total Timesteps: 532662 Episode Num: 610 Reward: 483.0069376096798\n",
      "Total Timesteps: 533662 Episode Num: 611 Reward: 647.9260480420949\n",
      "Total Timesteps: 534662 Episode Num: 612 Reward: 645.276004269842\n",
      "Total Timesteps: 535662 Episode Num: 613 Reward: 672.1570981180641\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 413.880486\n",
      "---------------------------------------\n",
      "Total Timesteps: 536662 Episode Num: 614 Reward: 534.6153487160855\n",
      "Total Timesteps: 537662 Episode Num: 615 Reward: 657.9945727605639\n",
      "Total Timesteps: 538662 Episode Num: 616 Reward: 500.0898483326551\n",
      "Total Timesteps: 539662 Episode Num: 617 Reward: 877.183758480337\n",
      "Total Timesteps: 540662 Episode Num: 618 Reward: 724.0028905953146\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 640.977141\n",
      "---------------------------------------\n",
      "Total Timesteps: 541662 Episode Num: 619 Reward: 586.9413955587582\n",
      "Total Timesteps: 542662 Episode Num: 620 Reward: 275.2932975885866\n",
      "Total Timesteps: 543662 Episode Num: 621 Reward: 599.833148660479\n",
      "Total Timesteps: 544662 Episode Num: 622 Reward: 612.6173622403841\n",
      "Total Timesteps: 545662 Episode Num: 623 Reward: 171.61164365897693\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 493.625269\n",
      "---------------------------------------\n",
      "Total Timesteps: 546662 Episode Num: 624 Reward: 715.6996310988892\n",
      "Total Timesteps: 547662 Episode Num: 625 Reward: 603.5083051144928\n",
      "Total Timesteps: 548662 Episode Num: 626 Reward: 547.0808936329847\n",
      "Total Timesteps: 549662 Episode Num: 627 Reward: 608.1974840043081\n",
      "Total Timesteps: 550662 Episode Num: 628 Reward: 666.2683688164145\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 629.947718\n",
      "---------------------------------------\n",
      "Total Timesteps: 551662 Episode Num: 629 Reward: 636.0602395182681\n",
      "Total Timesteps: 552662 Episode Num: 630 Reward: 534.3747681465097\n",
      "Total Timesteps: 553662 Episode Num: 631 Reward: 620.8134011433119\n",
      "Total Timesteps: 554662 Episode Num: 632 Reward: 662.2043852668113\n",
      "Total Timesteps: 555662 Episode Num: 633 Reward: 731.1455854399487\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 538.657432\n",
      "---------------------------------------\n",
      "Total Timesteps: 556662 Episode Num: 634 Reward: 461.92072748046587\n",
      "Total Timesteps: 557662 Episode Num: 635 Reward: 372.2019040323845\n",
      "Total Timesteps: 558662 Episode Num: 636 Reward: 473.56776102399965\n",
      "Total Timesteps: 559662 Episode Num: 637 Reward: 511.8363193283587\n",
      "Total Timesteps: 560662 Episode Num: 638 Reward: 598.8341916815178\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 669.173365\n",
      "---------------------------------------\n",
      "Total Timesteps: 561662 Episode Num: 639 Reward: 590.4047796452322\n",
      "Total Timesteps: 562662 Episode Num: 640 Reward: 532.792861723768\n",
      "Total Timesteps: 563662 Episode Num: 641 Reward: 456.43404897131876\n",
      "Total Timesteps: 564662 Episode Num: 642 Reward: 541.2001581301824\n",
      "Total Timesteps: 565662 Episode Num: 643 Reward: 757.6791803907323\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 490.096863\n",
      "---------------------------------------\n",
      "Total Timesteps: 566662 Episode Num: 644 Reward: 652.1777242787838\n",
      "Total Timesteps: 567662 Episode Num: 645 Reward: 777.6276520273079\n",
      "Total Timesteps: 568662 Episode Num: 646 Reward: 670.5544924335703\n",
      "Total Timesteps: 569662 Episode Num: 647 Reward: 479.3614525195369\n",
      "Total Timesteps: 570662 Episode Num: 648 Reward: 390.8014357033776\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 618.855448\n",
      "---------------------------------------\n",
      "Total Timesteps: 571662 Episode Num: 649 Reward: 785.5473312967418\n",
      "Total Timesteps: 572662 Episode Num: 650 Reward: 543.7530500416167\n",
      "Total Timesteps: 573662 Episode Num: 651 Reward: 510.8120356359545\n",
      "Total Timesteps: 574662 Episode Num: 652 Reward: 668.4765636950766\n",
      "Total Timesteps: 575662 Episode Num: 653 Reward: 457.7499400212935\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 560.422317\n",
      "---------------------------------------\n",
      "Total Timesteps: 576662 Episode Num: 654 Reward: 525.3932621764317\n",
      "Total Timesteps: 577662 Episode Num: 655 Reward: 494.74160409210214\n",
      "Total Timesteps: 578662 Episode Num: 656 Reward: 725.6211334125767\n",
      "Total Timesteps: 579662 Episode Num: 657 Reward: 428.017981607994\n",
      "Total Timesteps: 580662 Episode Num: 658 Reward: 926.5712781963642\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 565.681620\n",
      "---------------------------------------\n",
      "Total Timesteps: 581662 Episode Num: 659 Reward: 390.13647716056755\n",
      "Total Timesteps: 582662 Episode Num: 660 Reward: 415.651697818272\n",
      "Total Timesteps: 583662 Episode Num: 661 Reward: 784.1524491558737\n",
      "Total Timesteps: 584662 Episode Num: 662 Reward: 600.4308891055232\n",
      "Total Timesteps: 585662 Episode Num: 663 Reward: 369.3631117342102\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 507.067454\n",
      "---------------------------------------\n",
      "Total Timesteps: 586662 Episode Num: 664 Reward: 342.75015013186487\n",
      "Total Timesteps: 587662 Episode Num: 665 Reward: 555.0130018918878\n",
      "Total Timesteps: 588662 Episode Num: 666 Reward: 782.9008146956144\n",
      "Total Timesteps: 589662 Episode Num: 667 Reward: 349.0489847279387\n",
      "Total Timesteps: 590662 Episode Num: 668 Reward: 448.88919127166054\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 527.152852\n",
      "---------------------------------------\n",
      "Total Timesteps: 591662 Episode Num: 669 Reward: 704.5210253136418\n",
      "Total Timesteps: 592662 Episode Num: 670 Reward: 239.30913290214386\n",
      "Total Timesteps: 593662 Episode Num: 671 Reward: 524.3204499772821\n",
      "Total Timesteps: 594662 Episode Num: 672 Reward: 447.1518757872693\n",
      "Total Timesteps: 595662 Episode Num: 673 Reward: 524.9900113313182\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 471.457966\n",
      "---------------------------------------\n",
      "Total Timesteps: 596662 Episode Num: 674 Reward: 696.7661499264373\n",
      "Total Timesteps: 597662 Episode Num: 675 Reward: 377.432321384063\n",
      "Total Timesteps: 598662 Episode Num: 676 Reward: 612.2126297457944\n",
      "Total Timesteps: 599662 Episode Num: 677 Reward: 483.2893911327029\n",
      "Total Timesteps: 600662 Episode Num: 678 Reward: 483.09301177204344\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 375.333805\n",
      "---------------------------------------\n",
      "Total Timesteps: 601662 Episode Num: 679 Reward: 429.8398188176238\n",
      "Total Timesteps: 602662 Episode Num: 680 Reward: 417.87611926345863\n",
      "Total Timesteps: 603662 Episode Num: 681 Reward: 455.32481192547885\n",
      "Total Timesteps: 604662 Episode Num: 682 Reward: 777.1906751408524\n",
      "Total Timesteps: 605662 Episode Num: 683 Reward: 432.6677116026437\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 510.628427\n",
      "---------------------------------------\n",
      "Total Timesteps: 606662 Episode Num: 684 Reward: 422.1161842828883\n",
      "Total Timesteps: 607662 Episode Num: 685 Reward: 550.4268876601242\n",
      "Total Timesteps: 608662 Episode Num: 686 Reward: 512.2263562702119\n",
      "Total Timesteps: 609662 Episode Num: 687 Reward: 789.0332585530185\n",
      "Total Timesteps: 610662 Episode Num: 688 Reward: 786.1912853008403\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 488.145002\n",
      "---------------------------------------\n",
      "Total Timesteps: 611662 Episode Num: 689 Reward: 223.9997724120574\n",
      "Total Timesteps: 612662 Episode Num: 690 Reward: 561.4253468531111\n",
      "Total Timesteps: 613662 Episode Num: 691 Reward: 666.129827801982\n",
      "Total Timesteps: 614662 Episode Num: 692 Reward: 678.8126052287931\n",
      "Total Timesteps: 615662 Episode Num: 693 Reward: 554.3093640353874\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 311.487318\n",
      "---------------------------------------\n",
      "Total Timesteps: 616662 Episode Num: 694 Reward: 388.3416552796994\n",
      "Total Timesteps: 617662 Episode Num: 695 Reward: 492.59111438868865\n",
      "Total Timesteps: 618662 Episode Num: 696 Reward: 832.0416609207102\n",
      "Total Timesteps: 619662 Episode Num: 697 Reward: 375.20374824237985\n",
      "Total Timesteps: 620662 Episode Num: 698 Reward: 187.74489464504583\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 319.202081\n",
      "---------------------------------------\n",
      "Total Timesteps: 621662 Episode Num: 699 Reward: 663.5364036356439\n",
      "Total Timesteps: 622662 Episode Num: 700 Reward: 477.43660955253887\n",
      "Total Timesteps: 623662 Episode Num: 701 Reward: 354.89177526811176\n",
      "Total Timesteps: 624662 Episode Num: 702 Reward: 270.66283931647666\n",
      "Total Timesteps: 625662 Episode Num: 703 Reward: 595.3528852067975\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 335.057494\n",
      "---------------------------------------\n",
      "Total Timesteps: 626662 Episode Num: 704 Reward: 334.66962919579584\n",
      "Total Timesteps: 627662 Episode Num: 705 Reward: 297.9461979804366\n",
      "Total Timesteps: 628662 Episode Num: 706 Reward: 543.2098555119239\n",
      "Total Timesteps: 629662 Episode Num: 707 Reward: 524.9371382086541\n",
      "Total Timesteps: 630662 Episode Num: 708 Reward: 688.3985266768373\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 467.368599\n",
      "---------------------------------------\n",
      "Total Timesteps: 631662 Episode Num: 709 Reward: 481.08092930384106\n",
      "Total Timesteps: 632662 Episode Num: 710 Reward: 557.6485264145147\n",
      "Total Timesteps: 633662 Episode Num: 711 Reward: 626.8695052356437\n",
      "Total Timesteps: 634662 Episode Num: 712 Reward: 546.4846031051159\n",
      "Total Timesteps: 635662 Episode Num: 713 Reward: 402.5011511385976\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 576.320462\n",
      "---------------------------------------\n",
      "Total Timesteps: 636662 Episode Num: 714 Reward: 387.817312294702\n",
      "Total Timesteps: 637662 Episode Num: 715 Reward: 528.6277400740637\n",
      "Total Timesteps: 638662 Episode Num: 716 Reward: 388.1607980615223\n",
      "Total Timesteps: 639662 Episode Num: 717 Reward: 576.4677918524302\n",
      "Total Timesteps: 640662 Episode Num: 718 Reward: 468.07374473257386\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 441.651720\n",
      "---------------------------------------\n",
      "Total Timesteps: 641662 Episode Num: 719 Reward: 555.7375068015809\n",
      "Total Timesteps: 642662 Episode Num: 720 Reward: 794.3558826673785\n",
      "Total Timesteps: 643662 Episode Num: 721 Reward: 874.2212762484667\n",
      "Total Timesteps: 644662 Episode Num: 722 Reward: 483.67616105152536\n",
      "Total Timesteps: 645662 Episode Num: 723 Reward: 661.3904884271923\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 544.787227\n",
      "---------------------------------------\n",
      "Total Timesteps: 646662 Episode Num: 724 Reward: 805.5409592910299\n",
      "Total Timesteps: 647662 Episode Num: 725 Reward: 755.6581381965003\n",
      "Total Timesteps: 648662 Episode Num: 726 Reward: 380.29886190953414\n",
      "Total Timesteps: 649662 Episode Num: 727 Reward: 602.0204733206147\n",
      "Total Timesteps: 650662 Episode Num: 728 Reward: 466.0621285771245\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 557.275015\n",
      "---------------------------------------\n",
      "Total Timesteps: 651662 Episode Num: 729 Reward: 523.5172536107259\n",
      "Total Timesteps: 652662 Episode Num: 730 Reward: 553.1049588329961\n",
      "Total Timesteps: 653662 Episode Num: 731 Reward: 536.0916308261706\n",
      "Total Timesteps: 654662 Episode Num: 732 Reward: 494.8202304971375\n",
      "Total Timesteps: 655662 Episode Num: 733 Reward: 679.3876364798051\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 532.553265\n",
      "---------------------------------------\n",
      "Total Timesteps: 656662 Episode Num: 734 Reward: 476.27960539281935\n",
      "Total Timesteps: 657662 Episode Num: 735 Reward: 677.0540852476264\n",
      "Total Timesteps: 658662 Episode Num: 736 Reward: 710.3787342449602\n",
      "Total Timesteps: 659662 Episode Num: 737 Reward: 692.2907380781054\n",
      "Total Timesteps: 660662 Episode Num: 738 Reward: 563.0831268463816\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 691.808315\n",
      "---------------------------------------\n",
      "Total Timesteps: 661662 Episode Num: 739 Reward: 635.9319574617354\n",
      "Total Timesteps: 662662 Episode Num: 740 Reward: 811.612388701943\n",
      "Total Timesteps: 663662 Episode Num: 741 Reward: 675.601928014148\n",
      "Total Timesteps: 664662 Episode Num: 742 Reward: 486.3530018819134\n",
      "Total Timesteps: 665662 Episode Num: 743 Reward: 682.9008872608523\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 640.063755\n",
      "---------------------------------------\n",
      "Total Timesteps: 666662 Episode Num: 744 Reward: 666.878500289159\n",
      "Total Timesteps: 667662 Episode Num: 745 Reward: 673.462060188803\n",
      "Total Timesteps: 668662 Episode Num: 746 Reward: 1026.090282399236\n",
      "Total Timesteps: 669662 Episode Num: 747 Reward: 788.5226094697775\n",
      "Total Timesteps: 670662 Episode Num: 748 Reward: 944.9340955495506\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 843.411804\n",
      "---------------------------------------\n",
      "Total Timesteps: 671662 Episode Num: 749 Reward: 921.9718859456344\n",
      "Total Timesteps: 672662 Episode Num: 750 Reward: 606.3852166314005\n",
      "Total Timesteps: 673662 Episode Num: 751 Reward: 1003.8058934906563\n",
      "Total Timesteps: 674662 Episode Num: 752 Reward: 799.6002732041668\n",
      "Total Timesteps: 675662 Episode Num: 753 Reward: 655.4692721508051\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 805.125412\n",
      "---------------------------------------\n",
      "Total Timesteps: 676662 Episode Num: 754 Reward: 529.8392432793274\n",
      "Total Timesteps: 677662 Episode Num: 755 Reward: 675.3173870224107\n",
      "Total Timesteps: 678662 Episode Num: 756 Reward: 1111.6999249993278\n",
      "Total Timesteps: 679662 Episode Num: 757 Reward: 932.5650101731675\n",
      "Total Timesteps: 680662 Episode Num: 758 Reward: 684.9408262665602\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 888.445075\n",
      "---------------------------------------\n",
      "Total Timesteps: 681662 Episode Num: 759 Reward: 950.7080356053724\n",
      "Total Timesteps: 682662 Episode Num: 760 Reward: 811.0465482282638\n",
      "Total Timesteps: 683662 Episode Num: 761 Reward: 1151.6671538669177\n",
      "Total Timesteps: 684662 Episode Num: 762 Reward: 900.5728590619985\n",
      "Total Timesteps: 685662 Episode Num: 763 Reward: 1055.6653057238711\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 822.458385\n",
      "---------------------------------------\n",
      "Total Timesteps: 686662 Episode Num: 764 Reward: 716.4988201774585\n",
      "Total Timesteps: 687662 Episode Num: 765 Reward: 589.8835835490834\n",
      "Total Timesteps: 688662 Episode Num: 766 Reward: 761.898225034003\n",
      "Total Timesteps: 689662 Episode Num: 767 Reward: 828.3025694384389\n",
      "Total Timesteps: 690662 Episode Num: 768 Reward: 636.6179037292526\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 703.789057\n",
      "---------------------------------------\n",
      "Total Timesteps: 691662 Episode Num: 769 Reward: 770.2050384533733\n",
      "Total Timesteps: 692662 Episode Num: 770 Reward: 948.6678067718406\n",
      "Total Timesteps: 693662 Episode Num: 771 Reward: 680.7288465020923\n",
      "Total Timesteps: 694662 Episode Num: 772 Reward: 636.1803165087223\n",
      "Total Timesteps: 695662 Episode Num: 773 Reward: 1056.0161674732362\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 889.273898\n",
      "---------------------------------------\n",
      "Total Timesteps: 696662 Episode Num: 774 Reward: 984.0525504208089\n",
      "Total Timesteps: 697662 Episode Num: 775 Reward: 1110.09169587006\n",
      "Total Timesteps: 698662 Episode Num: 776 Reward: 1011.9262233131409\n",
      "Total Timesteps: 699662 Episode Num: 777 Reward: 763.8037023000638\n",
      "Total Timesteps: 700662 Episode Num: 778 Reward: 890.6534000052947\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 890.103417\n",
      "---------------------------------------\n",
      "Total Timesteps: 701662 Episode Num: 779 Reward: 960.4085107016683\n",
      "Total Timesteps: 702662 Episode Num: 780 Reward: 1136.9125636938986\n",
      "Total Timesteps: 703662 Episode Num: 781 Reward: 645.9472162854946\n",
      "Total Timesteps: 704662 Episode Num: 782 Reward: 830.363049944317\n",
      "Total Timesteps: 705662 Episode Num: 783 Reward: 1026.8093417547439\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 834.552828\n",
      "---------------------------------------\n",
      "Total Timesteps: 706662 Episode Num: 784 Reward: 740.2651396579984\n",
      "Total Timesteps: 707662 Episode Num: 785 Reward: 776.9350323604802\n",
      "Total Timesteps: 708662 Episode Num: 786 Reward: 1065.8406257124652\n",
      "Total Timesteps: 709662 Episode Num: 787 Reward: 1172.0561474199174\n",
      "Total Timesteps: 710662 Episode Num: 788 Reward: 847.6948856024744\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 937.927275\n",
      "---------------------------------------\n",
      "Total Timesteps: 711662 Episode Num: 789 Reward: 795.4023403021994\n",
      "Total Timesteps: 712662 Episode Num: 790 Reward: 1254.9146673221367\n",
      "Total Timesteps: 713662 Episode Num: 791 Reward: 1322.9914682876035\n",
      "Total Timesteps: 714662 Episode Num: 792 Reward: 823.8757947424155\n",
      "Total Timesteps: 715662 Episode Num: 793 Reward: 1323.9694045693534\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1161.589558\n",
      "---------------------------------------\n",
      "Total Timesteps: 716662 Episode Num: 794 Reward: 1240.7318010747158\n",
      "Total Timesteps: 717662 Episode Num: 795 Reward: 1145.3030320422627\n",
      "Total Timesteps: 718662 Episode Num: 796 Reward: 866.181592896771\n",
      "Total Timesteps: 719662 Episode Num: 797 Reward: 1031.5162911054745\n",
      "Total Timesteps: 720662 Episode Num: 798 Reward: 789.312248960098\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1224.240897\n",
      "---------------------------------------\n",
      "Total Timesteps: 721541 Episode Num: 799 Reward: 976.7060922891659\n",
      "Total Timesteps: 722541 Episode Num: 800 Reward: 1136.5237295826416\n",
      "Total Timesteps: 723541 Episode Num: 801 Reward: 1390.512632358313\n",
      "Total Timesteps: 724541 Episode Num: 802 Reward: 1317.448832674124\n",
      "Total Timesteps: 725541 Episode Num: 803 Reward: 1280.0796342032477\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1217.231371\n",
      "---------------------------------------\n",
      "Total Timesteps: 726541 Episode Num: 804 Reward: 1015.9524439466489\n",
      "Total Timesteps: 727541 Episode Num: 805 Reward: 898.8064418455599\n",
      "Total Timesteps: 728541 Episode Num: 806 Reward: 1066.7172443669745\n",
      "Total Timesteps: 729541 Episode Num: 807 Reward: 828.5411835234111\n",
      "Total Timesteps: 730541 Episode Num: 808 Reward: 589.8633005354641\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 840.104422\n",
      "---------------------------------------\n",
      "Total Timesteps: 731541 Episode Num: 809 Reward: 880.473507782586\n",
      "Total Timesteps: 732541 Episode Num: 810 Reward: 687.2841035409796\n",
      "Total Timesteps: 733541 Episode Num: 811 Reward: 720.2076313648187\n",
      "Total Timesteps: 734541 Episode Num: 812 Reward: 564.155791821925\n",
      "Total Timesteps: 735114 Episode Num: 813 Reward: 448.5887941571675\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 660.851129\n",
      "---------------------------------------\n",
      "Total Timesteps: 736114 Episode Num: 814 Reward: 767.0480817011022\n",
      "Total Timesteps: 737114 Episode Num: 815 Reward: 392.72816834000105\n",
      "Total Timesteps: 738114 Episode Num: 816 Reward: 1100.7977858532113\n",
      "Total Timesteps: 739114 Episode Num: 817 Reward: 1069.8081299033627\n",
      "Total Timesteps: 740114 Episode Num: 818 Reward: 1052.0152829090619\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 709.785687\n",
      "---------------------------------------\n",
      "Total Timesteps: 741114 Episode Num: 819 Reward: 591.26616240191\n",
      "Total Timesteps: 742114 Episode Num: 820 Reward: 1133.8048568773852\n",
      "Total Timesteps: 743114 Episode Num: 821 Reward: 702.0920336381942\n",
      "Total Timesteps: 744114 Episode Num: 822 Reward: 765.7125522489686\n",
      "Total Timesteps: 745114 Episode Num: 823 Reward: 1194.8756510352903\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 733.044877\n",
      "---------------------------------------\n",
      "Total Timesteps: 746114 Episode Num: 824 Reward: 664.3143536358713\n",
      "Total Timesteps: 747114 Episode Num: 825 Reward: 800.9738195665154\n",
      "Total Timesteps: 748114 Episode Num: 826 Reward: 1511.7146922956183\n",
      "Total Timesteps: 749114 Episode Num: 827 Reward: 1125.5555556062661\n",
      "Total Timesteps: 750114 Episode Num: 828 Reward: 313.60100992766644\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1110.792349\n",
      "---------------------------------------\n",
      "Total Timesteps: 751114 Episode Num: 829 Reward: 1343.0218596374245\n",
      "Total Timesteps: 752114 Episode Num: 830 Reward: 1355.3170345797275\n",
      "Total Timesteps: 753114 Episode Num: 831 Reward: 1353.4194966309933\n",
      "Total Timesteps: 754114 Episode Num: 832 Reward: 1335.0233557443053\n",
      "Total Timesteps: 755114 Episode Num: 833 Reward: 1305.7146331739211\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1343.293113\n",
      "---------------------------------------\n",
      "Total Timesteps: 756114 Episode Num: 834 Reward: 1472.390473960683\n",
      "Total Timesteps: 757114 Episode Num: 835 Reward: 1460.885210938799\n",
      "Total Timesteps: 758114 Episode Num: 836 Reward: 1381.9308447131325\n",
      "Total Timesteps: 759114 Episode Num: 837 Reward: 1304.586149254395\n",
      "Total Timesteps: 760114 Episode Num: 838 Reward: 1321.0531479921135\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1245.431893\n",
      "---------------------------------------\n",
      "Total Timesteps: 761114 Episode Num: 839 Reward: 1233.4250587166612\n",
      "Total Timesteps: 762114 Episode Num: 840 Reward: 1357.1508401592973\n",
      "Total Timesteps: 763114 Episode Num: 841 Reward: 1313.4971727425739\n",
      "Total Timesteps: 764114 Episode Num: 842 Reward: 1131.8567548251872\n",
      "Total Timesteps: 765114 Episode Num: 843 Reward: 1314.9713234684455\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1237.626240\n",
      "---------------------------------------\n",
      "Total Timesteps: 766114 Episode Num: 844 Reward: 1267.1639138813414\n",
      "Total Timesteps: 767114 Episode Num: 845 Reward: 1466.5284131296105\n",
      "Total Timesteps: 768114 Episode Num: 846 Reward: 1455.6220424525009\n",
      "Total Timesteps: 769114 Episode Num: 847 Reward: 1583.6825896669163\n",
      "Total Timesteps: 770114 Episode Num: 848 Reward: 1509.7551362702518\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1483.369077\n",
      "---------------------------------------\n",
      "Total Timesteps: 771114 Episode Num: 849 Reward: 1462.4764306153402\n",
      "Total Timesteps: 772114 Episode Num: 850 Reward: 1432.6604891731242\n",
      "Total Timesteps: 773114 Episode Num: 851 Reward: 1547.5748405244967\n",
      "Total Timesteps: 774114 Episode Num: 852 Reward: 1071.2788347982578\n",
      "Total Timesteps: 775114 Episode Num: 853 Reward: 1564.1173694604336\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1545.561680\n",
      "---------------------------------------\n",
      "Total Timesteps: 776114 Episode Num: 854 Reward: 1443.721279947009\n",
      "Total Timesteps: 777114 Episode Num: 855 Reward: 1229.871156768817\n",
      "Total Timesteps: 778114 Episode Num: 856 Reward: 1344.463449898513\n",
      "Total Timesteps: 779114 Episode Num: 857 Reward: 1360.2021404681807\n",
      "Total Timesteps: 780114 Episode Num: 858 Reward: 1374.6233001563394\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1432.276188\n",
      "---------------------------------------\n",
      "Total Timesteps: 781114 Episode Num: 859 Reward: 1376.735466983646\n",
      "Total Timesteps: 782114 Episode Num: 860 Reward: 1256.8167257157813\n",
      "Total Timesteps: 783114 Episode Num: 861 Reward: 1392.9750372133115\n",
      "Total Timesteps: 784114 Episode Num: 862 Reward: 1405.1999794595984\n",
      "Total Timesteps: 785114 Episode Num: 863 Reward: 1259.967810751306\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1418.213520\n",
      "---------------------------------------\n",
      "Total Timesteps: 786114 Episode Num: 864 Reward: 1379.3024846986968\n",
      "Total Timesteps: 787114 Episode Num: 865 Reward: 1493.695821406709\n",
      "Total Timesteps: 788114 Episode Num: 866 Reward: 1574.8929607160244\n",
      "Total Timesteps: 789114 Episode Num: 867 Reward: 1554.8751400889764\n",
      "Total Timesteps: 790114 Episode Num: 868 Reward: 1713.4275874521434\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1501.956445\n",
      "---------------------------------------\n",
      "Total Timesteps: 791114 Episode Num: 869 Reward: 1481.7705380191276\n",
      "Total Timesteps: 792114 Episode Num: 870 Reward: 1607.1509366796722\n",
      "Total Timesteps: 793114 Episode Num: 871 Reward: 1458.5602336286072\n",
      "Total Timesteps: 794114 Episode Num: 872 Reward: 1405.6958239373128\n",
      "Total Timesteps: 795114 Episode Num: 873 Reward: 1510.9800856807726\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1528.250306\n",
      "---------------------------------------\n",
      "Total Timesteps: 796114 Episode Num: 874 Reward: 1615.0832573506236\n",
      "Total Timesteps: 797114 Episode Num: 875 Reward: 1575.6808687683217\n",
      "Total Timesteps: 798114 Episode Num: 876 Reward: 1465.7406937894975\n",
      "Total Timesteps: 799114 Episode Num: 877 Reward: 981.086654958734\n",
      "Total Timesteps: 800114 Episode Num: 878 Reward: 1509.4732591268419\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1359.535188\n",
      "---------------------------------------\n",
      "Total Timesteps: 801114 Episode Num: 879 Reward: 1232.7717330669902\n",
      "Total Timesteps: 802114 Episode Num: 880 Reward: 1657.432962978799\n",
      "Total Timesteps: 803114 Episode Num: 881 Reward: 1752.0152470953926\n",
      "Total Timesteps: 804114 Episode Num: 882 Reward: 1511.1937707817071\n",
      "Total Timesteps: 805114 Episode Num: 883 Reward: 1642.444953025315\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1626.057822\n",
      "---------------------------------------\n",
      "Total Timesteps: 806114 Episode Num: 884 Reward: 1670.7745458505763\n",
      "Total Timesteps: 807114 Episode Num: 885 Reward: 1733.7628504388497\n",
      "Total Timesteps: 808114 Episode Num: 886 Reward: 1663.9514842995025\n",
      "Total Timesteps: 809114 Episode Num: 887 Reward: 1605.3853276973969\n",
      "Total Timesteps: 810114 Episode Num: 888 Reward: 1733.701675139752\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1592.753216\n",
      "---------------------------------------\n",
      "Total Timesteps: 811114 Episode Num: 889 Reward: 1540.3735324042987\n",
      "Total Timesteps: 812114 Episode Num: 890 Reward: 1687.2191834216094\n",
      "Total Timesteps: 813114 Episode Num: 891 Reward: 1773.1872686135994\n",
      "Total Timesteps: 814114 Episode Num: 892 Reward: 1667.3555577396696\n",
      "Total Timesteps: 815114 Episode Num: 893 Reward: 1626.7501279203327\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1598.225026\n",
      "---------------------------------------\n",
      "Total Timesteps: 816114 Episode Num: 894 Reward: 1672.1786528863722\n",
      "Total Timesteps: 817114 Episode Num: 895 Reward: 1418.3931925404568\n",
      "Total Timesteps: 818114 Episode Num: 896 Reward: 1530.4539380114952\n",
      "Total Timesteps: 819114 Episode Num: 897 Reward: 1687.04905967835\n",
      "Total Timesteps: 820114 Episode Num: 898 Reward: 1647.117277713399\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1535.480127\n",
      "---------------------------------------\n",
      "Total Timesteps: 821114 Episode Num: 899 Reward: 1564.6448303306427\n",
      "Total Timesteps: 822114 Episode Num: 900 Reward: 1703.5119791154889\n",
      "Total Timesteps: 823114 Episode Num: 901 Reward: 1469.2289218717358\n",
      "Total Timesteps: 824114 Episode Num: 902 Reward: 1335.9027658256443\n",
      "Total Timesteps: 825114 Episode Num: 903 Reward: 1686.9783498708807\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1341.649545\n",
      "---------------------------------------\n",
      "Total Timesteps: 826114 Episode Num: 904 Reward: 1333.0866197174919\n",
      "Total Timesteps: 827114 Episode Num: 905 Reward: 1626.2368909490633\n",
      "Total Timesteps: 828114 Episode Num: 906 Reward: 1630.9485099416606\n",
      "Total Timesteps: 829114 Episode Num: 907 Reward: 1715.0910509746645\n",
      "Total Timesteps: 830114 Episode Num: 908 Reward: 1667.7105845422332\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1842.600337\n",
      "---------------------------------------\n",
      "Total Timesteps: 831114 Episode Num: 909 Reward: 1830.2675665162271\n",
      "Total Timesteps: 832114 Episode Num: 910 Reward: 1685.676371783694\n",
      "Total Timesteps: 833114 Episode Num: 911 Reward: 1786.7932230369258\n",
      "Total Timesteps: 834114 Episode Num: 912 Reward: 1670.3936943318035\n",
      "Total Timesteps: 835114 Episode Num: 913 Reward: 1803.3131977619444\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1825.789165\n",
      "---------------------------------------\n",
      "Total Timesteps: 836114 Episode Num: 914 Reward: 1823.4279941818538\n",
      "Total Timesteps: 837114 Episode Num: 915 Reward: 1743.5381303891845\n",
      "Total Timesteps: 838114 Episode Num: 916 Reward: 1678.2617181339513\n",
      "Total Timesteps: 839114 Episode Num: 917 Reward: 1753.520969972986\n",
      "Total Timesteps: 840114 Episode Num: 918 Reward: 1818.284422162014\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1955.889065\n",
      "---------------------------------------\n",
      "Total Timesteps: 841114 Episode Num: 919 Reward: 1753.6182369648782\n",
      "Total Timesteps: 842114 Episode Num: 920 Reward: 1822.81462635904\n",
      "Total Timesteps: 843114 Episode Num: 921 Reward: 1784.906534107564\n",
      "Total Timesteps: 844114 Episode Num: 922 Reward: 1853.252301145825\n",
      "Total Timesteps: 845114 Episode Num: 923 Reward: 1690.8974263346531\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1877.154098\n",
      "---------------------------------------\n",
      "Total Timesteps: 846114 Episode Num: 924 Reward: 1873.5195608098343\n",
      "Total Timesteps: 847114 Episode Num: 925 Reward: 1853.0266682515762\n",
      "Total Timesteps: 848114 Episode Num: 926 Reward: 1780.7008314984114\n",
      "Total Timesteps: 849114 Episode Num: 927 Reward: 1948.5278845974485\n",
      "Total Timesteps: 850114 Episode Num: 928 Reward: 1859.6609166751116\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1855.895463\n",
      "---------------------------------------\n",
      "Total Timesteps: 851114 Episode Num: 929 Reward: 1869.6476675830509\n",
      "Total Timesteps: 852114 Episode Num: 930 Reward: 1926.9746136910626\n",
      "Total Timesteps: 853114 Episode Num: 931 Reward: 2094.3052168263807\n",
      "Total Timesteps: 854114 Episode Num: 932 Reward: 1898.1099058180196\n",
      "Total Timesteps: 855114 Episode Num: 933 Reward: 1866.5900642226375\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1694.580284\n",
      "---------------------------------------\n",
      "Total Timesteps: 856114 Episode Num: 934 Reward: 1840.7894361408541\n",
      "Total Timesteps: 857114 Episode Num: 935 Reward: 1758.599277041415\n",
      "Total Timesteps: 858114 Episode Num: 936 Reward: 1891.2571703380856\n",
      "Total Timesteps: 859114 Episode Num: 937 Reward: 1939.9682100340672\n",
      "Total Timesteps: 859428 Episode Num: 938 Reward: 395.8093358365166\n",
      "Total Timesteps: 860428 Episode Num: 939 Reward: 1955.9089941048908\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1297.826715\n",
      "---------------------------------------\n",
      "Total Timesteps: 861428 Episode Num: 940 Reward: 1672.0505803073481\n",
      "Total Timesteps: 862428 Episode Num: 941 Reward: 1740.510891084574\n",
      "Total Timesteps: 863428 Episode Num: 942 Reward: 1871.805617772221\n",
      "Total Timesteps: 864428 Episode Num: 943 Reward: 1889.2534508106792\n",
      "Total Timesteps: 865428 Episode Num: 944 Reward: 1921.5643816794068\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1629.421078\n",
      "---------------------------------------\n",
      "Total Timesteps: 866428 Episode Num: 945 Reward: 1602.6853899696907\n",
      "Total Timesteps: 867428 Episode Num: 946 Reward: 1783.8709249450735\n",
      "Total Timesteps: 868428 Episode Num: 947 Reward: 1935.907668700171\n",
      "Total Timesteps: 869428 Episode Num: 948 Reward: 1686.9606958274082\n",
      "Total Timesteps: 870428 Episode Num: 949 Reward: 2004.5732036999495\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1890.014077\n",
      "---------------------------------------\n",
      "Total Timesteps: 871428 Episode Num: 950 Reward: 1848.0097112064136\n",
      "Total Timesteps: 872428 Episode Num: 951 Reward: 1796.2586582040594\n",
      "Total Timesteps: 873428 Episode Num: 952 Reward: 2007.9697719631356\n",
      "Total Timesteps: 874428 Episode Num: 953 Reward: 1998.0271609142922\n",
      "Total Timesteps: 875428 Episode Num: 954 Reward: 2027.8895123847574\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 2012.884269\n",
      "---------------------------------------\n",
      "Total Timesteps: 876428 Episode Num: 955 Reward: 2010.9659526548955\n",
      "Total Timesteps: 877428 Episode Num: 956 Reward: 1844.3981048989956\n",
      "Total Timesteps: 878428 Episode Num: 957 Reward: 1994.6586331185779\n",
      "Total Timesteps: 879428 Episode Num: 958 Reward: 2094.033787897631\n",
      "Total Timesteps: 880428 Episode Num: 959 Reward: 2101.119544801948\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1881.186050\n",
      "---------------------------------------\n",
      "Total Timesteps: 881428 Episode Num: 960 Reward: 1804.138087487123\n",
      "Total Timesteps: 882428 Episode Num: 961 Reward: 1921.782887605846\n",
      "Total Timesteps: 883428 Episode Num: 962 Reward: 1985.5645798797534\n",
      "Total Timesteps: 884428 Episode Num: 963 Reward: 1830.521692448097\n",
      "Total Timesteps: 885428 Episode Num: 964 Reward: 2127.496585369611\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1708.964378\n",
      "---------------------------------------\n",
      "Total Timesteps: 886428 Episode Num: 965 Reward: 1708.2163957487028\n",
      "Total Timesteps: 887428 Episode Num: 966 Reward: 2051.792034855013\n",
      "Total Timesteps: 888428 Episode Num: 967 Reward: 1906.5652802420082\n",
      "Total Timesteps: 889428 Episode Num: 968 Reward: 1898.0135336277965\n",
      "Total Timesteps: 890428 Episode Num: 969 Reward: 1973.1972161819992\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1733.762776\n",
      "---------------------------------------\n",
      "Total Timesteps: 891428 Episode Num: 970 Reward: 1793.5106773196214\n",
      "Total Timesteps: 892428 Episode Num: 971 Reward: 1910.7608374272563\n",
      "Total Timesteps: 893428 Episode Num: 972 Reward: 1955.40745225172\n",
      "Total Timesteps: 894428 Episode Num: 973 Reward: 1702.0269086767776\n",
      "Total Timesteps: 895428 Episode Num: 974 Reward: 1920.387669102267\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1853.694644\n",
      "---------------------------------------\n",
      "Total Timesteps: 896428 Episode Num: 975 Reward: 1845.199962842636\n",
      "Total Timesteps: 897428 Episode Num: 976 Reward: 1916.8394274365821\n",
      "Total Timesteps: 898428 Episode Num: 977 Reward: 1827.3112838134618\n",
      "Total Timesteps: 899428 Episode Num: 978 Reward: 1827.3635433576608\n",
      "Total Timesteps: 900428 Episode Num: 979 Reward: 2015.6249150438582\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 2076.404962\n",
      "---------------------------------------\n",
      "Total Timesteps: 901428 Episode Num: 980 Reward: 1920.3389517029916\n",
      "Total Timesteps: 902428 Episode Num: 981 Reward: 1846.8640099495076\n",
      "Total Timesteps: 903428 Episode Num: 982 Reward: 1988.4689630281587\n",
      "Total Timesteps: 904428 Episode Num: 983 Reward: 1927.619010245959\n",
      "Total Timesteps: 905428 Episode Num: 984 Reward: 1833.7663559914645\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 2089.574449\n",
      "---------------------------------------\n",
      "Total Timesteps: 906428 Episode Num: 985 Reward: 1987.3161010503873\n",
      "Total Timesteps: 907428 Episode Num: 986 Reward: 2051.2328586083286\n",
      "Total Timesteps: 908428 Episode Num: 987 Reward: 1874.129726417104\n",
      "Total Timesteps: 909428 Episode Num: 988 Reward: 2120.546839497434\n",
      "Total Timesteps: 910428 Episode Num: 989 Reward: 2057.69842234059\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1750.693128\n",
      "---------------------------------------\n",
      "Total Timesteps: 911428 Episode Num: 990 Reward: 1987.7349079191579\n",
      "Total Timesteps: 912428 Episode Num: 991 Reward: 1908.4648874790696\n",
      "Total Timesteps: 913428 Episode Num: 992 Reward: 1767.104718334007\n",
      "Total Timesteps: 914428 Episode Num: 993 Reward: 1665.399233581471\n",
      "Total Timesteps: 915428 Episode Num: 994 Reward: 1801.0886672489935\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1715.953038\n",
      "---------------------------------------\n",
      "Total Timesteps: 916428 Episode Num: 995 Reward: 1703.3455735697933\n",
      "Total Timesteps: 917428 Episode Num: 996 Reward: 1742.3225078419791\n",
      "Total Timesteps: 918428 Episode Num: 997 Reward: 1821.8854620160887\n",
      "Total Timesteps: 919428 Episode Num: 998 Reward: 2008.5298222511813\n",
      "Total Timesteps: 920428 Episode Num: 999 Reward: 1937.3885077804205\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1877.220092\n",
      "---------------------------------------\n",
      "Total Timesteps: 921428 Episode Num: 1000 Reward: 1985.4525091304627\n",
      "Total Timesteps: 922428 Episode Num: 1001 Reward: 1966.4576879813606\n",
      "Total Timesteps: 923428 Episode Num: 1002 Reward: 1501.6677180256074\n",
      "Total Timesteps: 924428 Episode Num: 1003 Reward: 1940.4788784139955\n",
      "Total Timesteps: 925428 Episode Num: 1004 Reward: 1999.5417527739532\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1995.684262\n",
      "---------------------------------------\n",
      "Total Timesteps: 926428 Episode Num: 1005 Reward: 2059.766162854857\n",
      "Total Timesteps: 927428 Episode Num: 1006 Reward: 2038.625328833192\n",
      "Total Timesteps: 928428 Episode Num: 1007 Reward: 1912.970071109333\n",
      "Total Timesteps: 929428 Episode Num: 1008 Reward: 2001.6792239918886\n",
      "Total Timesteps: 930428 Episode Num: 1009 Reward: 1977.246666889907\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1859.202567\n",
      "---------------------------------------\n",
      "Total Timesteps: 931428 Episode Num: 1010 Reward: 1922.3629399827257\n",
      "Total Timesteps: 932428 Episode Num: 1011 Reward: 1944.827727653788\n",
      "Total Timesteps: 933428 Episode Num: 1012 Reward: 2182.1167420140437\n",
      "Total Timesteps: 934428 Episode Num: 1013 Reward: 2213.507509653464\n",
      "Total Timesteps: 935428 Episode Num: 1014 Reward: 1962.459814998552\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 2027.161410\n",
      "---------------------------------------\n",
      "Total Timesteps: 936428 Episode Num: 1015 Reward: 1976.652340388334\n",
      "Total Timesteps: 937428 Episode Num: 1016 Reward: 2047.919211866471\n",
      "Total Timesteps: 938428 Episode Num: 1017 Reward: 2090.369761288816\n",
      "Total Timesteps: 939428 Episode Num: 1018 Reward: 2072.2604652177624\n",
      "Total Timesteps: 940428 Episode Num: 1019 Reward: 2166.6869514272994\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 2121.260774\n",
      "---------------------------------------\n",
      "Total Timesteps: 941428 Episode Num: 1020 Reward: 2261.75704317122\n",
      "Total Timesteps: 942428 Episode Num: 1021 Reward: 2159.903910275361\n",
      "Total Timesteps: 943428 Episode Num: 1022 Reward: 2200.100758335766\n",
      "Total Timesteps: 944428 Episode Num: 1023 Reward: 2026.7176667796866\n",
      "Total Timesteps: 945428 Episode Num: 1024 Reward: 1799.2079036002615\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1964.448649\n",
      "---------------------------------------\n",
      "Total Timesteps: 946428 Episode Num: 1025 Reward: 2052.51973644722\n",
      "Total Timesteps: 947428 Episode Num: 1026 Reward: 2063.7569679166313\n",
      "Total Timesteps: 948428 Episode Num: 1027 Reward: 2137.569229777709\n",
      "Total Timesteps: 949428 Episode Num: 1028 Reward: 2180.965211841016\n",
      "Total Timesteps: 950428 Episode Num: 1029 Reward: 2087.6641748059287\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 2228.358418\n",
      "---------------------------------------\n",
      "Total Timesteps: 951428 Episode Num: 1030 Reward: 2125.5985443038544\n",
      "Total Timesteps: 952428 Episode Num: 1031 Reward: 2108.963589168042\n",
      "Total Timesteps: 953428 Episode Num: 1032 Reward: 2252.9851120476474\n",
      "Total Timesteps: 954428 Episode Num: 1033 Reward: 2170.77923471921\n",
      "Total Timesteps: 955428 Episode Num: 1034 Reward: 2131.5389803380663\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 2189.079969\n",
      "---------------------------------------\n",
      "Total Timesteps: 956428 Episode Num: 1035 Reward: 2166.110339637243\n",
      "Total Timesteps: 957428 Episode Num: 1036 Reward: 2228.010250657852\n",
      "Total Timesteps: 958428 Episode Num: 1037 Reward: 2169.6413155749356\n",
      "Total Timesteps: 959428 Episode Num: 1038 Reward: 2200.1859676516647\n",
      "Total Timesteps: 960428 Episode Num: 1039 Reward: 2257.303390425526\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 2208.408556\n",
      "---------------------------------------\n",
      "Total Timesteps: 961428 Episode Num: 1040 Reward: 2193.348557975071\n",
      "Total Timesteps: 962428 Episode Num: 1041 Reward: 2211.7972099452486\n",
      "Total Timesteps: 963428 Episode Num: 1042 Reward: 2229.849133159991\n",
      "Total Timesteps: 964428 Episode Num: 1043 Reward: 2085.617123008416\n",
      "Total Timesteps: 965428 Episode Num: 1044 Reward: 2220.8330258283077\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 2163.046584\n",
      "---------------------------------------\n",
      "Total Timesteps: 966428 Episode Num: 1045 Reward: 2193.2880270728533\n",
      "Total Timesteps: 967428 Episode Num: 1046 Reward: 1969.5310190770451\n",
      "Total Timesteps: 968428 Episode Num: 1047 Reward: 1954.8489187233824\n",
      "Total Timesteps: 969428 Episode Num: 1048 Reward: 2020.1763116293198\n",
      "Total Timesteps: 970428 Episode Num: 1049 Reward: 1995.054264148569\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1995.624422\n",
      "---------------------------------------\n",
      "Total Timesteps: 971428 Episode Num: 1050 Reward: 1861.122873242616\n",
      "Total Timesteps: 972428 Episode Num: 1051 Reward: 2258.693129608488\n",
      "Total Timesteps: 973428 Episode Num: 1052 Reward: 2076.101124070043\n",
      "Total Timesteps: 974428 Episode Num: 1053 Reward: 2020.5822234543843\n",
      "Total Timesteps: 975428 Episode Num: 1054 Reward: 2124.310694586327\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 2233.038271\n",
      "---------------------------------------\n",
      "Total Timesteps: 976428 Episode Num: 1055 Reward: 2196.355547226336\n",
      "Total Timesteps: 977428 Episode Num: 1056 Reward: 2332.8796449931165\n",
      "Total Timesteps: 978428 Episode Num: 1057 Reward: 2324.0234133140525\n",
      "Total Timesteps: 979428 Episode Num: 1058 Reward: 2331.9999265986035\n",
      "Total Timesteps: 980428 Episode Num: 1059 Reward: 2308.900551302233\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 2124.295943\n",
      "---------------------------------------\n",
      "Total Timesteps: 981428 Episode Num: 1060 Reward: 2194.3925771381923\n",
      "Total Timesteps: 982428 Episode Num: 1061 Reward: 2217.319745556294\n",
      "Total Timesteps: 983428 Episode Num: 1062 Reward: 2266.8597343092547\n",
      "Total Timesteps: 984428 Episode Num: 1063 Reward: 2198.6927251866337\n",
      "Total Timesteps: 985428 Episode Num: 1064 Reward: 2163.6310739901314\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 2283.322328\n",
      "---------------------------------------\n",
      "Total Timesteps: 986428 Episode Num: 1065 Reward: 2294.602793667029\n",
      "Total Timesteps: 987428 Episode Num: 1066 Reward: 2221.030911858999\n",
      "Total Timesteps: 988428 Episode Num: 1067 Reward: 2337.4264320235065\n",
      "Total Timesteps: 989428 Episode Num: 1068 Reward: 2262.4701356900605\n",
      "Total Timesteps: 990428 Episode Num: 1069 Reward: 2297.5710793534895\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 1924.399713\n",
      "---------------------------------------\n",
      "Total Timesteps: 991428 Episode Num: 1070 Reward: 2175.1030694558053\n",
      "Total Timesteps: 992428 Episode Num: 1071 Reward: 2161.0892270562476\n",
      "Total Timesteps: 993428 Episode Num: 1072 Reward: 2391.067707947815\n",
      "Total Timesteps: 994428 Episode Num: 1073 Reward: 2212.0142770591788\n",
      "Total Timesteps: 995428 Episode Num: 1074 Reward: 2185.3000072506493\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 2243.837391\n",
      "---------------------------------------\n",
      "Total Timesteps: 996428 Episode Num: 1075 Reward: 2223.9111755997646\n",
      "Total Timesteps: 997428 Episode Num: 1076 Reward: 2321.5244841632607\n",
      "Total Timesteps: 998428 Episode Num: 1077 Reward: 2307.148817968626\n",
      "Total Timesteps: 999428 Episode Num: 1078 Reward: 2230.858979127265\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 2267.611870\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# We start the main loop over 500,000 timesteps\n",
    "while total_timesteps < max_timesteps:\n",
    "  \n",
    "  # If the episode is done\n",
    "  if done:\n",
    "\n",
    "    # If we are not at the very beginning, we start the training process of the model\n",
    "    if total_timesteps != 0:\n",
    "      print(\"Total Timesteps: {} Episode Num: {} Reward: {}\".format(total_timesteps, episode_num, episode_reward))\n",
    "      policy.train(replay_buffer, episode_timesteps, batch_size, discount, tau, policy_noise, noise_clip, policy_freq)\n",
    "\n",
    "    # We evaluate the episode and we save the policy\n",
    "    if timesteps_since_eval >= eval_freq:\n",
    "      timesteps_since_eval %= eval_freq\n",
    "      evaluations.append(evaluate_policy(policy))\n",
    "      policy.save(file_name, directory=\"./pytorch_models\")\n",
    "      np.save(\"./results/%s\" % (file_name), evaluations)\n",
    "    \n",
    "    # When the training step is done, we reset the state of the environment\n",
    "    obs = env.reset()\n",
    "    \n",
    "    # Set the Done to False\n",
    "    done = False\n",
    "    \n",
    "    # Set rewards and episode timesteps to zero\n",
    "    episode_reward = 0\n",
    "    episode_timesteps = 0\n",
    "    episode_num += 1\n",
    "  \n",
    "  # Before 10000 timesteps, we play random actions\n",
    "  if total_timesteps < start_timesteps:\n",
    "    action = env.action_space.sample()\n",
    "  else: # After 10000 timesteps, we switch to the model\n",
    "    action = policy.select_action(np.array(obs))\n",
    "    # If the explore_noise parameter is not 0, we add noise to the action and we clip it\n",
    "    if expl_noise != 0:\n",
    "      action = (action + np.random.normal(0, expl_noise, size=env.action_space.shape[0])).clip(env.action_space.low, env.action_space.high)\n",
    "  \n",
    "  # The agent performs the action in the environment, then reaches the next state and receives the reward\n",
    "  new_obs, reward, done, _ = env.step(action)\n",
    "  \n",
    "  # We check if the episode is done\n",
    "  done_bool = 0 if episode_timesteps + 1 == env._max_episode_steps else float(done)\n",
    "  \n",
    "  # We increase the total reward\n",
    "  episode_reward += reward\n",
    "  \n",
    "  # We store the new transition into the Experience Replay memory (ReplayBuffer)\n",
    "  replay_buffer.add((obs, new_obs, action, reward, done_bool))\n",
    "\n",
    "  # We update the state, the episode timestep, the total timesteps, and the timesteps since the evaluation of the policy\n",
    "  obs = new_obs\n",
    "  episode_timesteps += 1\n",
    "  total_timesteps += 1\n",
    "  timesteps_since_eval += 1\n",
    "\n",
    "# We add the last policy evaluation to our list of evaluations and we save our model\n",
    "evaluations.append(evaluate_policy(policy))\n",
    "if save_models: policy.save(\"%s\" % (file_name), directory=\"./pytorch_models\")\n",
    "np.save(\"./results/%s\" % (file_name), evaluations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wi6e2-_pu05e"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oW4d1YAMqif1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------------------------------------\n",
      "Settings: TD3_AntBulletEnv-v0_0\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: 2174.793852\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import ffmpeg\n",
    "class Actor(nn.Module):\n",
    "  \n",
    "  def __init__(self, state_dim, action_dim, max_action):\n",
    "    super(Actor, self).__init__()\n",
    "    self.layer_1 = nn.Linear(state_dim, 400)\n",
    "    self.layer_2 = nn.Linear(400, 300)\n",
    "    self.layer_3 = nn.Linear(300, action_dim)\n",
    "    self.max_action = max_action\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.layer_1(x))\n",
    "    x = F.relu(self.layer_2(x))\n",
    "    x = self.max_action * torch.tanh(self.layer_3(x)) \n",
    "    return x\n",
    "\n",
    "class Critic(nn.Module):\n",
    "  \n",
    "  def __init__(self, state_dim, action_dim):\n",
    "    super(Critic, self).__init__()\n",
    "    # Defining the first Critic neural network\n",
    "    self.layer_1 = nn.Linear(state_dim + action_dim, 400)\n",
    "    self.layer_2 = nn.Linear(400, 300)\n",
    "    self.layer_3 = nn.Linear(300, 1)\n",
    "    # # Defining the second Critic neural network\n",
    "    # self.layer_4 = nn.Linear(state_dim + action_dim, 400)\n",
    "    # self.layer_5 = nn.Linear(400, 300)\n",
    "    # self.layer_6 = nn.Linear(300, 1)\n",
    "\n",
    "  def forward(self, x, u):\n",
    "    xu = torch.cat([x, u], 1)\n",
    "    # Forward-Propagation on the first Critic Neural Network\n",
    "    x1 = F.relu(self.layer_1(xu))\n",
    "    x1 = F.relu(self.layer_2(x1))\n",
    "    x1 = self.layer_3(x1)\n",
    "    # Forward-Propagation on the second Critic Neural Network\n",
    "    # x2 = F.relu(self.layer_4(xu))\n",
    "    # x2 = F.relu(self.layer_5(x2))\n",
    "    # x2 = self.layer_6(x2)\n",
    "    return x1\n",
    "  # def Q1(self, x, u):\n",
    "  #   xu = torch.cat([x, u], 1)\n",
    "  #   x1 = F.relu(self.layer_1(xu))\n",
    "  #   x1 = F.relu(self.layer_2(x1))\n",
    "  #   x1 = self.layer_3(x1)\n",
    "  #   return x1\n",
    "\n",
    "# Selecting the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Building the whole Training Process into a class\n",
    "\n",
    "class TD3(object):\n",
    "  \n",
    "  def __init__(self, state_dim, action_dim, max_action):\n",
    "    self.actor = Actor(state_dim, action_dim, max_action).to(device)\n",
    "    self.actor_target = Actor(state_dim, action_dim, max_action).to(device)\n",
    "    self.actor_target.load_state_dict(self.actor.state_dict())\n",
    "    self.actor_optimizer = torch.optim.Adam(self.actor.parameters())\n",
    "    self.critic = Critic(state_dim, action_dim).to(device)\n",
    "    self.critic_target = Critic(state_dim, action_dim).to(device)\n",
    "    self.critic_target.load_state_dict(self.critic.state_dict())\n",
    "    self.critic_optimizer = torch.optim.Adam(self.critic.parameters())\n",
    "    self.max_action = max_action\n",
    "\n",
    "  def select_action(self, state):\n",
    "    state = torch.Tensor(state.reshape(1, -1)).to(device)\n",
    "    return self.actor(state).cpu().data.numpy().flatten()\n",
    "\n",
    "  def train(self, replay_buffer, iterations, batch_size=100, discount=0.99, tau=0.005, policy_noise=0.2, noise_clip=0.5, policy_freq=2):\n",
    "    \n",
    "    for it in range(iterations):\n",
    "      \n",
    "      # Step 4: We sample a batch of transitions (s, s’, a, r) from the memory\n",
    "      batch_states, batch_next_states, batch_actions, batch_rewards, batch_dones = replay_buffer.sample(batch_size)\n",
    "      state = torch.Tensor(batch_states).to(device)\n",
    "      next_state = torch.Tensor(batch_next_states).to(device)\n",
    "      action = torch.Tensor(batch_actions).to(device)\n",
    "      reward = torch.Tensor(batch_rewards).to(device)\n",
    "      done = torch.Tensor(batch_dones).to(device)\n",
    "      \n",
    "      # Step 5: From the next state s’, the Actor target plays the next action a’\n",
    "      next_action = self.actor_target(next_state)\n",
    "      \n",
    "      # Step 6: We add Gaussian noise to this next action a’ and we clamp it in a range of values supported by the environment\n",
    "      noise = torch.Tensor(batch_actions).data.normal_(0, policy_noise).to(device)\n",
    "      noise = noise.clamp(-noise_clip, noise_clip)\n",
    "      next_action = (next_action + noise).clamp(-self.max_action, self.max_action)\n",
    "      \n",
    "      # Step 7: The two Critic targets take each the couple (s’, a’) as input and return two Q-values Qt1(s’,a’) and Qt2(s’,a’) as outputs\n",
    "      target_Q1= self.critic_target(next_state, next_action)\n",
    "      \n",
    "      # Step 8: We keep the minimum of these two Q-values: min(Qt1, Qt2)\n",
    "      # target_Q1 = torch.min(target_Q1, target_Q2)\n",
    "      \n",
    "      # Step 9: We get the final target of the two Critic models, which is: Qt = r + γ * min(Qt1, Qt2), where γ is the discount factor\n",
    "      target_Q1 = reward + ((1 - done) * discount * target_Q1).detach()\n",
    "      \n",
    "      # Step 10: The two Critic models take each the couple (s, a) as input and return two Q-values Q1(s,a) and Q2(s,a) as outputs\n",
    "      current_Q1 = self.critic(state, action)\n",
    "      \n",
    "      # Step 11: We compute the loss coming from the two Critic models: Critic Loss = MSE_Loss(Q1(s,a), Qt) + MSE_Loss(Q2(s,a), Qt)\n",
    "      critic_loss = F.mse_loss(current_Q1, target_Q1)\n",
    "      \n",
    "      # Step 12: We backpropagate this Critic loss and update the parameters of the two Critic models with a SGD optimizer\n",
    "      self.critic_optimizer.zero_grad()\n",
    "      critic_loss.backward()\n",
    "      self.critic_optimizer.step()\n",
    "      \n",
    "      # Step 13: Once every two iterations, we update our Actor model by performing gradient ascent on the output of the first Critic model\n",
    "      if it % policy_freq == 0:\n",
    "        actor_loss = -self.critic.forward(state, self.actor(state)).mean()\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "        \n",
    "        # Step 14: Still once every two iterations, we update the weights of the Actor target by polyak averaging\n",
    "        for param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
    "          target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
    "        \n",
    "        # Step 15: Still once every two iterations, we update the weights of the Critic target by polyak averaging\n",
    "        for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
    "          target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
    "  \n",
    "  # Making a save method to save a trained model\n",
    "  def save(self, filename, directory):\n",
    "    torch.save(self.actor.state_dict(), '%s/%s_actor.pth' % (directory, filename))\n",
    "    torch.save(self.critic.state_dict(), '%s/%s_critic.pth' % (directory, filename))\n",
    "  \n",
    "  # Making a load method to load a pre-trained model\n",
    "  def load(self, filename, directory):\n",
    "    self.actor.load_state_dict(torch.load('%s/%s_actor.pth' % (directory, filename)))\n",
    "    self.critic.load_state_dict(torch.load('%s/%s_critic.pth' % (directory, filename)))\n",
    "\n",
    "def evaluate_policy(policy, eval_episodes=10):\n",
    "  avg_reward = 0.\n",
    "  for _ in range(eval_episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "      action = policy.select_action(np.array(obs))\n",
    "      obs, reward, done, _ = env.step(action)\n",
    "      avg_reward += reward\n",
    "  avg_reward /= eval_episodes\n",
    "  print (\"---------------------------------------\")\n",
    "  print (\"Average Reward over the Evaluation Step: %f\" % (avg_reward))\n",
    "  print (\"---------------------------------------\")\n",
    "  return avg_reward\n",
    "\n",
    "env_name = \"AntBulletEnv-v0\"\n",
    "seed = 0\n",
    "\n",
    "file_name = \"%s_%s_%s\" % (\"TD3\", env_name, str(seed))\n",
    "print (\"---------------------------------------\")\n",
    "print (\"Settings: %s\" % (file_name))\n",
    "print (\"---------------------------------------\")\n",
    "\n",
    "eval_episodes = 10\n",
    "save_env_vid = True\n",
    "env = gym.make(env_name)\n",
    "max_episode_steps = env._max_episode_steps\n",
    "if save_env_vid:\n",
    "  env = wrappers.Monitor(env, monitor_dir, force = True)\n",
    "  env.reset()\n",
    "env.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "max_action = float(env.action_space.high[0])\n",
    "policy = TD3(state_dim, action_dim, max_action)\n",
    "policy.load(file_name, './pytorch_models/')\n",
    "_ = evaluate_policy(policy, eval_episodes=eval_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TD3_Ant.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}